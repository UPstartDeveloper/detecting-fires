{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire Image Classification\n",
    "\n",
    "How well can we build a neural network to classify images of fire?\n",
    "\n",
    "This is a binary classification problem. In this notebook we will use the Keras deep-learning API to explore the use of:\n",
    "\n",
    "- Convolutional Neural Network Architecture\n",
    "- Optimizing Neural Network Hyperparameters\n",
    "- Upsampling the Minority Class in an unbalanced Dataset\n",
    "- Augmenting the Images to Add Samples to the Dataset\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# Keras Imports\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "# CNN and MLP architecture\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    UpSampling2D,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    BatchNormalization\n",
    ")\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal\n",
    "# Keras Callbacks\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "# Time Training\n",
    "import time\n",
    "# Data Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Image Preprocessing\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "# Optimizing Hyperparameters\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "# Data Generator\n",
    "import util\n",
    "# Loading Model from JSON file\n",
    "from keras.models import model_from_json\n",
    "# Resampling function\n",
    "from sklearn.utils import resample\n",
    "# Data Augmentation of the Images\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Fire-Detection-Image-Dataset/fires.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Folder</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Normal Images 3</td>\n",
       "      <td>Hotel_Monterey_La_Soeur_Osaka_standard_twin_be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Normal Images 3</td>\n",
       "      <td>house5.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Normal Images 3</td>\n",
       "      <td>mi-plage-hawai.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Normal Images 3</td>\n",
       "      <td>JB224_03_Colourful_christmas_table_setting_in_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Normal Images 3</td>\n",
       "      <td>Interior Design Ideas (3).jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           Folder  \\\n",
       "0           0  Normal Images 3   \n",
       "1           1  Normal Images 3   \n",
       "2           2  Normal Images 3   \n",
       "3           3  Normal Images 3   \n",
       "4           4  Normal Images 3   \n",
       "\n",
       "                                            filename  label  \n",
       "0  Hotel_Monterey_La_Soeur_Osaka_standard_twin_be...      0  \n",
       "1                                         house5.jpg      0  \n",
       "2                                 mi-plage-hawai.jpg      0  \n",
       "3  JB224_03_Colourful_christmas_table_setting_in_...      0  \n",
       "4                      Interior Design Ideas (3).jpg      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define predictor and target sets of data\n",
    "features = [df.columns[1], df.columns[2]]\n",
    "target = [df.columns[3]]\n",
    "X, y = df[features], df[target]\n",
    "# Store number of class\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split DataFrame Based on Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Samples: 495\n",
      "Number of Testing Samples: 156\n"
     ]
    }
   ],
   "source": [
    "def split_data(df):\n",
    "    \"\"\"Split a DataFrame into training and testing sets.\n",
    "       Up to 75% of data will be used for training, the \n",
    "       rest is randomly selected for testing.\n",
    "    \n",
    "       Parameters:\n",
    "       df(pandas.DataFrame): overall dataset\n",
    "       \n",
    "       Return: tuple(DataFrame, DataFrame): \n",
    "                returns two DataFrame objects for \n",
    "                each subset of the data\n",
    "    \n",
    "    \"\"\"\n",
    "    # Split df into train and test, based on label\n",
    "    # Credit goes to this Stack Overflow answer for the following:\n",
    "    # https://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas\n",
    "    selector = np.random.rand(len(df)) < 0.75\n",
    "    df_train, df_test = df[selector], df[~selector]\n",
    "    return df_train, df_test\n",
    "\n",
    "def data():\n",
    "    \"\"\"Data providing function (will later use for Hyperas).\"\"\"\n",
    "    df = pd.read_csv('Fire-Detection-Image-Dataset/fires.csv')\n",
    "    selector = np.random.rand(len(df)) < 0.75\n",
    "    df_train, df_test = df[selector], df[~selector]\n",
    "    print(f\"Number of Training Samples: {len(df_train)}\")\n",
    "    print(f\"Number of Testing Samples: {len(df_test)}\")\n",
    "    return df_train, df_test\n",
    "\n",
    "df_train, df_test = data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Optimal Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Generator\n",
    "\n",
    "For this dataset, we'll increase the efficiency of training by loading in subsections of the dataset to train on at a time, using Python-esque generator in Keras!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_gen = util.data_gen\n",
    "def data_gen(df_gen, batch_size):\n",
    "    \"\"\"Generate batches of the dataset to train the model on, one subsection at a time.\n",
    "       Credit goes to Milad Toutounchian for this implementation, originally found at:\n",
    "       https://github.com/Make-School-Courses/DS-2.2-Deep-Learning/blob/master/Final_Project/image_data_prep.ipynb\n",
    "    \n",
    "       Parameters:\n",
    "       df(DataFrame): larger portion of the datset used for training\n",
    "       batch_size(int): the number of samples to include in each batch\n",
    "       \n",
    "       Returns:\n",
    "       tuple: input features of the batch, along with corresponding labels\n",
    "    \n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # list of images\n",
    "        x_batch = np.zeros((batch_size, 1024, 1024, 3))\n",
    "        # list of labels\n",
    "        y_batch = np.zeros((batch_size, 1))\n",
    "        # add samples until we reach batch size\n",
    "        for j in range(len(df_gen) // batch_size):\n",
    "            batch_index = 0\n",
    "            for index in df_gen['Unnamed: 0']:\n",
    "                if batch_index < batch_size:\n",
    "                    # add image to the input\n",
    "                    filepath = f\"Fire-Detection-Image-Dataset/{df_gen['Folder'][index]}/{df_gen['filename'][index]}\"\n",
    "                    img = Image.open(filepath)\n",
    "                    image_red = img.resize((1024, 1024))\n",
    "                    x_batch[batch_index] = img_to_array(image_red)\n",
    "                    # set label\n",
    "                    y_batch[batch_index] = df_gen['label'][index]\n",
    "                    # increment index in the batch\n",
    "                    batch_index += 1\n",
    "            yield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Best Architecture\n",
    "\n",
    "Now we'll find the optimal number of layers and neurons per layer using TensorBoard.\n",
    "\n",
    "To begin, it's time to define some **utility functions** that will make the rest of this analysis less redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to Reduce Repetition\n",
    "def add_conv_layer(model, layer_size, needs_input):\n",
    "    \"\"\"Add a Keras convolutional layer to the model, along with MaxPooling.\n",
    "       Will specify input shape as well if needed.\n",
    "       \n",
    "       Parameters:\n",
    "       model(Model): Neural network in Keras\n",
    "       layer_size(int): number of neurons to go in layer\n",
    "       need_input(bool): signals if the convolutional layer needs to specify\n",
    "                         the dimensions of the input\n",
    "       \n",
    "       Returns: None\n",
    "       \n",
    "    \"\"\"\n",
    "    if needs_input is True:\n",
    "        # specify input dimension for 1st conv layer\n",
    "        conv_layer = Conv2D(layer_size,\n",
    "                            kernel_size=(3, 3),\n",
    "                            activation='relu',\n",
    "                            input_shape=(1024, 1024, 3))\n",
    "\n",
    "    else:\n",
    "        # otherwise all other convolutional layers don't need it\n",
    "        conv_layer = Conv2D(layer_size,\n",
    "                            kernel_size=(3, 3),\n",
    "                            activation='relu')\n",
    "    # add Convolutional layer\n",
    "    model.add(conv_layer)  \n",
    "    # add MaxPooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  # no learning params\n",
    "    return None\n",
    "                  \n",
    "    \n",
    "def add_dense_layer(model, layer_size, is_output, drop_rate):\n",
    "    \"\"\"Add a multi-layer perceptron to the model\n",
    "       Will specify 'sigmoid' for the final layer.\n",
    "       \n",
    "       Parameters:\n",
    "       model(Model): Neural network in Keras\n",
    "       layer_size(int): number of neurons to go in layer\n",
    "       is_output(bdool): signals if the MLP is the last layer\n",
    "       drop_rate(float): percentage of connections in Dense layer\n",
    "                       to cut off\n",
    "       \n",
    "       Returns: None\n",
    "       \n",
    "    \"\"\"\n",
    "    # specify activation function\n",
    "    activation = 'relu' if is_output is False else 'sigmoid'\n",
    "    # add MLP\n",
    "    model.add(Dense(layer_size, activation=activation)) \n",
    "    # Add Dropout layer and Batch Normalization\n",
    "    if is_output is False:\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(drop_rate))\n",
    "    return None\n",
    "\n",
    "def compile_model(model):\n",
    "    \"\"\"Compile the neural network.\n",
    "    \n",
    "       Parameter:\n",
    "       model(keras.Sequential or keras.Model): the model object\n",
    "       \n",
    "       Returns: None\n",
    "       \n",
    "    \"\"\"\n",
    "    model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy',\n",
    "                           tf.keras.metrics.Precision(),\n",
    "                           tf.keras.metrics.Recall()])\n",
    "    return None\n",
    "\n",
    "def define_model(units, conv_layers, dense_layers, dropout):\n",
    "    \"\"\"Define a CNN + MLP model in Keras.\n",
    "    \n",
    "       Parameters:\n",
    "       units(int): number of neurons to go in a layer\n",
    "       conv_layers(int): number of convolutional layers\n",
    "       dense_layers(int): number of MLP\n",
    "       dropout(float): percentage of connections in Dense layer\n",
    "                       to cut off\n",
    "                       \n",
    "       Returns: tf.keras.Sequential: the neural network to train\n",
    "    \n",
    "    \"\"\"\n",
    "    # Instaniate model\n",
    "    model = Sequential()\n",
    "    # Add CNN layers\n",
    "    add_conv_layer(model, units, True)\n",
    "    for l in range(conv_layers - 1):\n",
    "        # add convolutional layers that come after the 1st\n",
    "        add_conv_layer(model, units, False)\n",
    "    # Flatten the data\n",
    "    model.add(Flatten())\n",
    "    # Add MLP Layers\n",
    "    for l in range(dense_layers - 1):\n",
    "        add_dense_layer(model, units, False, dropout)\n",
    "    # add final MLP, for output\n",
    "    add_dense_layer(model, 1, True, dropout)\n",
    "    # Compile Model\n",
    "    compile_model(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, df_training,\n",
    "                df_testing, epochs, \n",
    "                batch_size, callbacks,\n",
    "                steps_per_epoch=None,\n",
    "                val_steps=None):\n",
    "    \"\"\"Train the Keras model using a generator and callback functions.\n",
    "       \n",
    "       Parameters:\n",
    "       model(keras.Sequential or keras.Model): the model object\n",
    "       df_training(pd.DataFrame): subsection of the dataset for training\n",
    "       df_testing(pd.DataFrame): subsection of the dataset for testing\n",
    "       epochs(int): number of forward and back passes for the entire\n",
    "                    dataset through the model\n",
    "       batch_size(int): number of samples the model trains on in one \n",
    "                        batch (small subsection of the training data)\n",
    "       callbacks(List<function>): special Keras functions to improve models\n",
    "       \n",
    "       returns: History.history: a dict containing metrics about model\n",
    "       \n",
    "    \"\"\"\n",
    "    # train the model\n",
    "    history = model.fit_generator(generator=data_gen(df_training, batch_size=batch_size),\n",
    "                                steps_per_epoch=len(df_training['label']) // batch_size,\n",
    "                                epochs=epochs,\n",
    "                                validation_data=data_gen(df_testing, batch_size=batch_size),\n",
    "                                validation_steps=len(df_testing['label']) // batch_size, \n",
    "                                callbacks=callbacks)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zainraza/Downloads/dev/courses/DS/detecting-fires/env/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/zainraza/Downloads/dev/courses/DS/detecting-fires/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/zainraza/Downloads/dev/courses/DS/detecting-fires/env/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/zainraza/Downloads/dev/courses/DS/detecting-fires/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/zainraza/Downloads/dev/courses/DS/detecting-fires/env/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/zainraza/Downloads/dev/courses/DS/detecting-fires/env/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 62s 3s/step - loss: 0.8858 - accuracy: 0.9812 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "WARNING:tensorflow:From /Users/zainraza/Downloads/dev/courses/DS/detecting-fires/env/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 72s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 62s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 63s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 63s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 87s 4s/step - loss: 6.1026e-11 - accuracy: 1.0000 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 873s 36s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 68s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 68s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 75s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 81s 3s/step - loss: 0.1708 - accuracy: 0.9917 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 81s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 90s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 71s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 65s 3s/step - loss: 4.6359e-04 - accuracy: 1.0000 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 65s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 63s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 100s 4s/step - loss: 1.4490 - accuracy: 0.9646 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 99s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 98s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 101s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 102s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "24/24 [==============================] - 111s 5s/step - loss: 1.0770e-12 - accuracy: 1.0000 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 4.1001e-14 - val_accuracy: 1.0000 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 113s 5s/step - loss: 5.3876e-14 - accuracy: 1.0000 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.7559e-14 - val_accuracy: 1.0000 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 114s 5s/step - loss: 3.1342e-14 - accuracy: 1.0000 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.3258e-14 - val_accuracy: 1.0000 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 107s 4s/step - loss: 2.4618e-14 - accuracy: 1.0000 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.0881e-14 - val_accuracy: 1.0000 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 109s 5s/step - loss: 2.0272e-14 - accuracy: 1.0000 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 9.1331e-15 - val_accuracy: 1.0000 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 103s 4s/step - loss: 0.2360 - accuracy: 0.9875 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 98s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 100s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 101s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 101s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 149s 6s/step - loss: 2.5329e-27 - accuracy: 1.0000 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1.1932e-20 - val_accuracy: 1.0000 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 145s 6s/step - loss: 2.5329e-27 - accuracy: 1.0000 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1.1932e-20 - val_accuracy: 1.0000 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 147s 6s/step - loss: 2.5329e-27 - accuracy: 1.0000 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1.1932e-20 - val_accuracy: 1.0000 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 140s 6s/step - loss: 2.5329e-27 - accuracy: 1.0000 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1.1932e-20 - val_accuracy: 1.0000 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 146s 6s/step - loss: 2.5329e-27 - accuracy: 1.0000 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1.1932e-20 - val_accuracy: 1.0000 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 163s 7s/step - loss: 0.9541 - accuracy: 0.9667 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 162s 7s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 168s 7s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 176s 7s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 181s 8s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 78s 3s/step - loss: 0.6798 - accuracy: 0.9854 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00 - val_loss: 0.6535 - val_accuracy: 1.0000 - val_precision_9: 0.0000e+00 - val_recall_9: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 74s 3s/step - loss: 0.6361 - accuracy: 1.0000 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00 - val_loss: 0.6163 - val_accuracy: 1.0000 - val_precision_9: 0.0000e+00 - val_recall_9: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 78s 3s/step - loss: 0.5970 - accuracy: 1.0000 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00 - val_loss: 0.5791 - val_accuracy: 1.0000 - val_precision_9: 0.0000e+00 - val_recall_9: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 71s 3s/step - loss: 0.5577 - accuracy: 1.0000 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00 - val_loss: 0.5408 - val_accuracy: 1.0000 - val_precision_9: 0.0000e+00 - val_recall_9: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 71s 3s/step - loss: 0.5202 - accuracy: 1.0000 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00 - val_loss: 0.5021 - val_accuracy: 1.0000 - val_precision_9: 0.0000e+00 - val_recall_9: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 125s 5s/step - loss: 0.7660 - accuracy: 0.3521 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 3.3938 - val_accuracy: 0.0500 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 107s 4s/step - loss: 0.7110 - accuracy: 0.4271 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 2.1975 - val_accuracy: 0.0500 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 97s 4s/step - loss: 0.6545 - accuracy: 0.5625 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 1.0859 - val_accuracy: 0.1000 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 86s 4s/step - loss: 0.6175 - accuracy: 0.6708 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 0.7147 - val_accuracy: 0.3500 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 84s 4s/step - loss: 0.5649 - accuracy: 0.7937 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 0.4170 - val_accuracy: 1.0000 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 83s 3s/step - loss: 0.7795 - accuracy: 0.5125 - precision_11: 0.0000e+00 - recall_11: 0.0000e+00 - val_loss: 0.0489 - val_accuracy: 1.0000 - val_precision_11: 0.0000e+00 - val_recall_11: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 71s 3s/step - loss: 0.7200 - accuracy: 0.4479 - precision_11: 0.0000e+00 - recall_11: 0.0000e+00 - val_loss: 0.0857 - val_accuracy: 1.0000 - val_precision_11: 0.0000e+00 - val_recall_11: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 76s 3s/step - loss: 0.6716 - accuracy: 0.6146 - precision_11: 0.0000e+00 - recall_11: 0.0000e+00 - val_loss: 0.1688 - val_accuracy: 1.0000 - val_precision_11: 0.0000e+00 - val_recall_11: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "24/24 [==============================] - 75s 3s/step - loss: 0.6369 - accuracy: 0.6438 - precision_11: 0.0000e+00 - recall_11: 0.0000e+00 - val_loss: 0.3559 - val_accuracy: 0.9500 - val_precision_11: 0.0000e+00 - val_recall_11: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 74s 3s/step - loss: 0.5971 - accuracy: 0.7500 - precision_11: 0.0000e+00 - recall_11: 0.0000e+00 - val_loss: 0.3577 - val_accuracy: 0.9500 - val_precision_11: 0.0000e+00 - val_recall_11: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 67s 3s/step - loss: 0.7814 - accuracy: 0.3979 - precision_12: 0.0000e+00 - recall_12: 0.0000e+00 - val_loss: 0.4248 - val_accuracy: 0.7500 - val_precision_12: 0.0000e+00 - val_recall_12: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 64s 3s/step - loss: 0.7308 - accuracy: 0.4187 - precision_12: 0.0000e+00 - recall_12: 0.0000e+00 - val_loss: 0.5950 - val_accuracy: 0.6500 - val_precision_12: 0.0000e+00 - val_recall_12: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 65s 3s/step - loss: 0.6413 - accuracy: 0.5271 - precision_12: 0.0000e+00 - recall_12: 0.0000e+00 - val_loss: 0.6571 - val_accuracy: 0.6500 - val_precision_12: 0.0000e+00 - val_recall_12: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 69s 3s/step - loss: 0.5755 - accuracy: 0.7125 - precision_12: 0.0000e+00 - recall_12: 0.0000e+00 - val_loss: 0.5744 - val_accuracy: 0.8500 - val_precision_12: 0.0000e+00 - val_recall_12: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 72s 3s/step - loss: 0.5404 - accuracy: 0.8750 - precision_12: 0.0000e+00 - recall_12: 0.0000e+00 - val_loss: 0.5530 - val_accuracy: 0.8500 - val_precision_12: 0.0000e+00 - val_recall_12: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 96s 4s/step - loss: 0.8362 - accuracy: 0.5021 - precision_13: 0.0000e+00 - recall_13: 0.0000e+00 - val_loss: 7.9876e-04 - val_accuracy: 1.0000 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.6878 - accuracy: 0.5792 - precision_13: 0.0000e+00 - recall_13: 0.0000e+00 - val_loss: 0.1214 - val_accuracy: 1.0000 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 90s 4s/step - loss: 0.6110 - accuracy: 0.7375 - precision_13: 0.0000e+00 - recall_13: 0.0000e+00 - val_loss: 0.2291 - val_accuracy: 1.0000 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 83s 3s/step - loss: 0.5553 - accuracy: 0.8250 - precision_13: 0.0000e+00 - recall_13: 0.0000e+00 - val_loss: 0.2225 - val_accuracy: 1.0000 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 87s 4s/step - loss: 0.5374 - accuracy: 0.8542 - precision_13: 0.0000e+00 - recall_13: 0.0000e+00 - val_loss: 0.3717 - val_accuracy: 1.0000 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 94s 4s/step - loss: 0.6979 - accuracy: 0.5542 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.2303 - val_accuracy: 1.0000 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 104s 4s/step - loss: 0.6472 - accuracy: 0.7000 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.4248 - val_accuracy: 1.0000 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 102s 4s/step - loss: 0.5917 - accuracy: 0.9042 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.4715 - val_accuracy: 1.0000 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 94s 4s/step - loss: 0.5453 - accuracy: 0.9563 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.4479 - val_accuracy: 1.0000 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.5018 - accuracy: 0.9667 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.4173 - val_accuracy: 1.0000 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 105s 4s/step - loss: 0.8518 - accuracy: 0.4563 - precision_15: 0.0000e+00 - recall_15: 0.0000e+00 - val_loss: 2.2416 - val_accuracy: 0.0000e+00 - val_precision_15: 0.0000e+00 - val_recall_15: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 94s 4s/step - loss: 0.6867 - accuracy: 0.6125 - precision_15: 0.0000e+00 - recall_15: 0.0000e+00 - val_loss: 0.9189 - val_accuracy: 0.1500 - val_precision_15: 0.0000e+00 - val_recall_15: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 90s 4s/step - loss: 0.5796 - accuracy: 0.7583 - precision_15: 0.0000e+00 - recall_15: 0.0000e+00 - val_loss: 0.6090 - val_accuracy: 0.8000 - val_precision_15: 0.0000e+00 - val_recall_15: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 89s 4s/step - loss: 0.5186 - accuracy: 0.8729 - precision_15: 0.0000e+00 - recall_15: 0.0000e+00 - val_loss: 0.5069 - val_accuracy: 1.0000 - val_precision_15: 0.0000e+00 - val_recall_15: 0.0000e+00\n",
      "Epoch 5/5\n",
      " 9/24 [==========>...................] - ETA: 51s - loss: 0.4655 - accuracy: 0.9389 - precision_15: 0.0000e+00 - recall_15: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "# Choices for the Model Architecture - values arbitrary\n",
    "dense_layers = [1, 2, 3]\n",
    "layer_sizes = [4, 8, 16]\n",
    "conv_layers = [1, 2, 3]\n",
    "\n",
    "# try different combinations!\n",
    "# These for loops come from https://youtu.be/lV09_8432VA\n",
    "for dense_layer in dense_layers:\n",
    "    for size in layer_sizes:\n",
    "        for conv in conv_layers:\n",
    "            # name the combo\n",
    "            NAME = (\n",
    "                f'{conv}-conv-{size}-nodes' +\n",
    "                f'-{dense_layer}-dense_layers' + \n",
    "                f'-{int(time.time())}'\n",
    "            )\n",
    "            # Instantiate TensorBoard to visualize model performance\n",
    "            tensorboard = TensorBoard(log_dir=f'./Graph/{NAME}')\n",
    "            # Define Model\n",
    "            model = define_model(size, conv, dense_layer, 0.2)\n",
    "            # Train the Model (using a generator!)\n",
    "            epochs, batch_size = 5, 20\n",
    "            history = train_model(model, df_train, df_test, epochs, \n",
    "                                  batch_size, [tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Conclusion: What's the Best Architecture for the Model?**\n",
    "\n",
    "After training the different combinations above and looking through the [logs](Graph/) returned by Tensorboard, the best model archtecture has been determined to be:\n",
    "\n",
    "- 3 Conv2D Layers\n",
    "- 1 Dense Layer\n",
    "- 4 Neurons in each Layer\n",
    "- Dropout Rate of 20%\n",
    "- 5 epochs\n",
    "- 20 samples per Batch\n",
    "\n",
    "This model had the following metrics, which was the best of any of the other models:\n",
    "\n",
    "- Validation Accuracy: 100%\n",
    "- Validation Loss: 4.51e31%\n",
    "- Validation Precision: 96.25%\n",
    "- Validation Recall: 95.09%\n",
    "- F1-Score: 0.9567\n",
    "\n",
    "Although the accuracy of 100% is a little concerning, it may be possible to prevent overfitting by increase the drop out rate to 30%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Finding Optimal Hyperparameters\n",
    "\n",
    "Now, we'll find the optimal values for the hyperparameters using hyperas...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    \"\"\"Returns a dictionary with the results of the best model.\"\"\"\n",
    "    # define known parameters\n",
    "    layer_size = 4\n",
    "    # Instaniate model\n",
    "    model = Sequential()\n",
    "    # Instantiate TensorBoard to visualize model performance\n",
    "    tensorboard = TensorBoard(log_dir='./Graph')\n",
    "    # Add 3 CNN layers\n",
    "    model.add(Conv2D(layer_size, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=(1024, 1024, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(layer_size,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(layer_size,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Flatten the data\n",
    "    model.add(Flatten())\n",
    "    # Add 1 MLP Layer\n",
    "    model.add(Dense(1, activation={{choice(['sigmoid', 'relu'])}}))\n",
    "    # Compile Model\n",
    "    model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                  optimizer=\n",
    "                      {{choice(\n",
    "                          [keras.optimizers.Adadelta(),\n",
    "                          'sgd', 'adam', 'rmsprop']   \n",
    "                           )}},\n",
    "                  metrics=['accuracy',\n",
    "                           tf.keras.metrics.Precision(),\n",
    "                           tf.keras.metrics.Recall()])\n",
    "    # Train Model   \n",
    "    batch_size={{choice([10, 20, 40])}}\n",
    "    history = model.fit_generator(generator=util.data_gen(df_train, batch_size=batch_size),\n",
    "                                steps_per_epoch=len(df_train['label']) // batch_size,\n",
    "                                epochs={{choice([3, 5, 7])}},\n",
    "                                validation_data=util.data_gen(df_test, batch_size=batch_size),\n",
    "                                validation_steps=len(df_test['label']) // batch_size, \n",
    "                                callbacks=[tensorboard])\n",
    "    \n",
    "    # Get Optimized results\n",
    "    # get the highest validation metrics of the training epochs\n",
    "    val_loss = np.amax(result.history['val_loss'])\n",
    "    print(f'Best validation acc of epoch: {(1-val_loss)}')\n",
    "    return {\n",
    "        'loss': val_loss,\n",
    "        'accuracy': 1-val_loss,\n",
    "        'status': STATUS_OK,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "# find the best model!\n",
    "best_run, best_model = optim.minimize(model=optimize_model,\n",
    "                                    data=data,\n",
    "                                    algo=tpe.suggest,\n",
    "                                    max_evals=5,\n",
    "                                    trials=Trials(),\n",
    "                                    notebook_name='classifications')\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Conclusion: What are the Optimal Hyperparameters?**\n",
    "\n",
    "After using Hyperas, the best hyperparameters appear to be the following (in order to balance model performance with overfitting and efficiency):\n",
    "\n",
    "- Activation Function (for the output layer): Sigmoid\n",
    "- Batch Size: 40\n",
    "- Epochs: 3\n",
    "- Optimizer: Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Summarize, and Save the Model\n",
    "\n",
    "This will help us for future reference, so when we want to make more improvements to the model we can simply load it from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_model = load_model('model_weights', 'model_architecture')\n",
    "print(optimal_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model\n",
    "\n",
    "We will define functions for both saving and loading the model (weights as well as architecture) from and Hadoop and JSON-formatted data.\n",
    "\n",
    "The name of the files the model will be saved to shall be: \n",
    "\n",
    "- 'model_weights.h5' (Hadoop format)\n",
    "- 'model_architecture.json' (Javascript Object Notation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, weights_file, architecture_file):\n",
    "    \"\"\"Save the model weights and architecture.\n",
    "    \n",
    "       Parameters: \n",
    "       model(Model): keras Model object being saved\n",
    "       weights_file(str): name of the Hadoop file where\n",
    "                          weights will be saved\n",
    "       architecture_file(str): name of the JSON file where \n",
    "                               model architecture is to be\n",
    "                               saved\n",
    "                               \n",
    "       Returns: None\n",
    "       \n",
    "    \"\"\"\n",
    "    # Save the weights\n",
    "    model.save_weights(f'{weights_file}.h5')\n",
    "    # Save the architecture\n",
    "    with open(f'{architecture_file}.json', 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_model(weights_file, architecture_file):\n",
    "    \"\"\"Read in the model weights and architecture.\n",
    "    \n",
    "       Parameters:\n",
    "       weights_file(str): name of the Hadoop file where\n",
    "                          weights loaded from\n",
    "       architecture_file(str): name of the JSON file where \n",
    "                               model architecture is read from\n",
    "                               \n",
    "       Returns: keras.Model: new model instantiated using the \n",
    "                             information from the files\n",
    "       \n",
    "    \"\"\"  \n",
    "    # Load Architecture\n",
    "    with open(f'{architecture_file}.json', 'r') as f:\n",
    "        new_model = model_from_json(f.read())\n",
    "    # Load Weights\n",
    "    new_model.load_weights(f'{weights_file}.h5')\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "save_model(optimal_model, 'model_weights', 'model_architecture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling the Minority Class\n",
    "\n",
    "We need more fire!\n",
    "\n",
    "The majority of images in this dataset are currently for the \"No fire\" class. Therefore our model is now biased towards predicting this class, which makes its accuracy less reliable. \n",
    "\n",
    "In order to deal with this problem, we'll randomly duplicate some of the existing fire images in our dataset, such that the ratio of both is more balanced.\n",
    "\n",
    "Look at [this blog post](https://elitedatascience.com/imbalanced-classes?_ga=2.44533796.1624997989.1593199508-1623274989.1547664151) for more info about this concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the DataFrame by classes\n",
    "df_no_fire = df[df['label'] == 0]\n",
    "df_fire = df[df['label'] == 1]\n",
    "# Upsampling by replacement:\n",
    "df_fire_upsampled = (\n",
    "    resample(df_fire, replace=True,\n",
    "             n_samples=len(df_no_fire), \n",
    "             random_state=123) # reproducible results\n",
    ")\n",
    "# Combine classes once more into one DataFrame\n",
    "df_upsampled = pd.concat([df_no_fire, df_fire_upsampled])\n",
    "# Verify class ratio is now 1:1\n",
    "df_upsampled['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's retrain the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model saved previously\n",
    "prev_biased_model = load_model('model_weights', 'model_architecture')\n",
    "# compile the model\n",
    "compile_model(prev_biased_model)\n",
    "# train-test split the data\n",
    "df_train, df_test = split_data(df_upsampled)\n",
    "# Retrain the model\n",
    "history = train_model(prev_biased_model, df_train, df_test, epochs=3, \n",
    "                       batch_size=40, callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint: Save the model again to make life easier!\n",
    "save_model(prev_biased_model, 'model_weights', 'model_architecture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augumentation\n",
    "\n",
    "Let's add more variation to the dataset now, in order to make the model more robust!\n",
    "\n",
    "Specifically, I will be using the code from this [lesson in DS 2.2](https://github.com/Make-School-Courses/DS-2.2-Deep-Learning/blob/master/Lessons/KerasforLargeDatasets.md) in order to generate new images of fire/no fire that may have the following alterations to them:\n",
    "\n",
    "- different positions of the fire, or other objects\n",
    "- different camera angles\n",
    "- weird lighting\n",
    "\n",
    "This will better prepare the model to be used on noisy, real world data in production!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define certain parameters for training\n",
    "image_dim = (1024, 1024)\n",
    "batch_size = 40\n",
    "dataset_dir = 'Fire-Detection-Image-Dataset'\n",
    "\n",
    "# Instantiate training ImageDataGenerator from Keras\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# Instantiate testing ImageDataGenerator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators for the new images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=image_dim,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=image_dim,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model saved previously\n",
    "prev_no_aug_model = load_model('model_weights', 'model_architecture')\n",
    "# Compile the model\n",
    "compile_model(prev_no_aug_model)\n",
    "# Train the model on augmented images, increased steps per epoch and validation steps\n",
    "history = prev_no_aug_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs=3,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800)\n",
    "\n",
    "history = train_model(optimal_model, df_train, df_test, epoch=3, \n",
    "                       batch_size=40, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint: Save the model again to make life easier!\n",
    "save_model(prev_no_aug_model, 'model_weights', 'model_architecture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Overall, how well did our model perform? In this section we will evaluate by understanding the following metrics, for how well the model classified validation data:\n",
    "\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n",
    "\n",
    "We will begin by loading in the model again, and compiling as well as training it such that it outputs accuracy, loss, precision, recall, and F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = load_model('model_weights', 'model_architecture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "# train model with callbacks, get history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "# calculate f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's verify the metrics we have available to us for plotting, in the `history` object returned by the training above (with augmented data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(metric):\n",
    "    \"\"\"Plots the model performance metric for training\n",
    "       testing data using Matplotlib.\n",
    "       \n",
    "       Parameters\n",
    "       metric(str): the name of the metric. Will be one of \n",
    "                    the keys in the History object, e.g. 'loss'\n",
    "       \n",
    "       Returns: None\n",
    "       \n",
    "    \"\"\"\n",
    "    # plot for training data\n",
    "    plt.plot(history.history[metric])\n",
    "    # plot for testing data\n",
    "    val_form = f'val_{metric}'\n",
    "    plt.plot(history.history[val_form])\n",
    "    # add meta-info about graph - title, labels, legend\n",
    "    plt.title(f'Model {metric}')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    # show the graph\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric('precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric('recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score\n",
    "```\n",
    "F1-Score = (2 * Precision * Recall) / (Precision + Recall)\n",
    "```\n",
    "This value below is an approximate answer, using estimated values for validation precision and recall from the graphs above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(precision, recall):\n",
    "    \"\"\"Return the F1-Score.\n",
    "    \n",
    "       Parameters:\n",
    "       precision(float): a proportion of the model's accurate positive predictions,\n",
    "                         out of all the positive predictions made by said model\n",
    "       recall(float): a proportion of the model's accurate positive predictions,\n",
    "                      to all the samples which were truly positive (TP and FN)\n",
    "                    \n",
    "       Returns: float: the F1-Score is a function of both precision and recall,\n",
    "                which especially becomes useful in datasets with unequal\n",
    "                distribution of classes\n",
    "    \n",
    "    \"\"\"\n",
    "    return (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "f1 = f1_score(0.831, 0.999)\n",
    "print(f'F1-Score of the Optimized Model: {round(f1, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Conclusions\n",
    "\n",
    "Ultimately, the model constructed had a validation accuracy of approximately 24.1% - this is bewildering, as the model still managed to score about 83.1% on validation precision, 99.9% on validation recall, and 0.907 for the F1-Score. This would suggest that the model is classifying both the minority and majority classes alright. \n",
    "\n",
    "To take this analysis further, I would train the model again and do the following:\n",
    "\n",
    "- Use the `EarlyStopping` callback function to get the best validation accuracy\n",
    "- Implement a function to exactly compute the F1-Score\n",
    "- Find the optimal kernel size\n",
    "- Find the optimal layer size for both the `Conv2D` and `Dense` layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
