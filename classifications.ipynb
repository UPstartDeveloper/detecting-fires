{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire Image Classification\n",
    "\n",
    "How well can we build a neural network to classify images of fire?\n",
    "\n",
    "This is a binary classification problem. In this notebook we will use the Keras deep-learning API to explore the use of:\n",
    "\n",
    "- Convolutional Neural Network Architecture\n",
    "- Optimizing Neural Network Hyperparameters\n",
    "- Upsampling the Minority Class in an unbalanced Dataset\n",
    "- Augmenting the Images to Add Samples to the Dataset\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# Keras Imports\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "# CNN and MLP architecture\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    UpSampling2D,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    BatchNormalization\n",
    ")\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal\n",
    "# Keras Callbacks\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "# Time Training\n",
    "import time\n",
    "# Data Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Image Preprocessing\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "# Optimizing Hyperparameters\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "# Data Generator\n",
    "import util\n",
    "# Loading Model from JSON file\n",
    "from keras.models import model_from_json\n",
    "# Resampling function\n",
    "from sklearn.utils import resample\n",
    "# Data Augmentation of the Images\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Fire-Detection-Image-Dataset/fires.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Folder</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Normal Images 3</td>\n",
       "      <td>Hotel_Monterey_La_Soeur_Osaka_standard_twin_be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Normal Images 3</td>\n",
       "      <td>house5.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Normal Images 3</td>\n",
       "      <td>mi-plage-hawai.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Normal Images 3</td>\n",
       "      <td>JB224_03_Colourful_christmas_table_setting_in_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Normal Images 3</td>\n",
       "      <td>Interior Design Ideas (3).jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           Folder  \\\n",
       "0           0  Normal Images 3   \n",
       "1           1  Normal Images 3   \n",
       "2           2  Normal Images 3   \n",
       "3           3  Normal Images 3   \n",
       "4           4  Normal Images 3   \n",
       "\n",
       "                                            filename  label  \n",
       "0  Hotel_Monterey_La_Soeur_Osaka_standard_twin_be...      0  \n",
       "1                                         house5.jpg      0  \n",
       "2                                 mi-plage-hawai.jpg      0  \n",
       "3  JB224_03_Colourful_christmas_table_setting_in_...      0  \n",
       "4                      Interior Design Ideas (3).jpg      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define predictor and target sets of data\n",
    "features = [df.columns[1], df.columns[2]]\n",
    "target = [df.columns[3]]\n",
    "X, y = df[features], df[target]\n",
    "# Store number of class\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split DataFrame Based on Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Samples: 495\n",
      "Number of Testing Samples: 156\n"
     ]
    }
   ],
   "source": [
    "def split_data(df):\n",
    "    \"\"\"Split a DataFrame into training and testing sets.\n",
    "       Up to 75% of data will be used for training, the \n",
    "       rest is randomly selected for testing.\n",
    "    \n",
    "       Parameters:\n",
    "       df(pandas.DataFrame): overall dataset\n",
    "       \n",
    "       Return: tuple(DataFrame, DataFrame): \n",
    "                returns two DataFrame objects for \n",
    "                each subset of the data\n",
    "    \n",
    "    \"\"\"\n",
    "    # Split df into train and test, based on label\n",
    "    # Credit goes to this Stack Overflow answer for the following:\n",
    "    # https://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas\n",
    "    selector = np.random.rand(len(df)) < 0.75\n",
    "    df_train, df_test = df[selector], df[~selector]\n",
    "    return df_train, df_test\n",
    "\n",
    "def data():\n",
    "    \"\"\"Data providing function (will later use for Hyperas).\"\"\"\n",
    "    df = pd.read_csv('Fire-Detection-Image-Dataset/fires.csv')\n",
    "    selector = np.random.rand(len(df)) < 0.75\n",
    "    df_train, df_test = df[selector], df[~selector]\n",
    "    print(f\"Number of Training Samples: {len(df_train)}\")\n",
    "    print(f\"Number of Testing Samples: {len(df_test)}\")\n",
    "    return df_train, df_test\n",
    "\n",
    "df_train, df_test = data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Optimal Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Generator\n",
    "\n",
    "For this dataset, we'll increase the efficiency of training by loading in subsections of the dataset to train on at a time, using Python-esque generator in Keras!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_gen = util.data_gen\n",
    "def data_gen(df_gen, batch_size):\n",
    "    \"\"\"Generate batches of the dataset to train the model on, one subsection at a time.\n",
    "       Credit goes to Milad Toutounchian for this implementation, originally found at:\n",
    "       https://github.com/Make-School-Courses/DS-2.2-Deep-Learning/blob/master/Final_Project/image_data_prep.ipynb\n",
    "    \n",
    "       Parameters:\n",
    "       df(DataFrame): larger portion of the datset used for training\n",
    "       batch_size(int): the number of samples to include in each batch\n",
    "       \n",
    "       Returns:\n",
    "       tuple: input features of the batch, along with corresponding labels\n",
    "    \n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # list of images\n",
    "        x_batch = np.zeros((batch_size, 1024, 1024, 3))\n",
    "        # list of labels\n",
    "        y_batch = np.zeros((batch_size, 1))\n",
    "        # add samples until we reach batch size\n",
    "        for j in range(len(df_gen) // batch_size):\n",
    "            batch_index = 0\n",
    "            for index in df_gen['Unnamed: 0']:\n",
    "                if batch_index < batch_size:\n",
    "                    # add image to the input\n",
    "                    filepath = f\"Fire-Detection-Image-Dataset/{df_gen['Folder'][index]}/{df_gen['filename'][index]}\"\n",
    "                    img = Image.open(filepath)\n",
    "                    image_red = img.resize((1024, 1024))\n",
    "                    x_batch[batch_index] = img_to_array(image_red)\n",
    "                    # set label\n",
    "                    y_batch[batch_index] = df_gen['label'][index]\n",
    "                    # increment index in the batch\n",
    "                    batch_index += 1\n",
    "            yield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Best Architecture\n",
    "\n",
    "Now we'll find the optimal number of layers and neurons per layer using TensorBoard.\n",
    "\n",
    "To begin, it's time to define some **utility functions** that will make the rest of this analysis less redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to Reduce Repetition\n",
    "def add_conv_layer(model, layer_size, needs_input, kernel_size=None, pool_size=None):\n",
    "    \"\"\"Add a Keras convolutional layer to the model, along with MaxPooling.\n",
    "       Will specify input shape as well if needed.\n",
    "       \n",
    "       Parameters:\n",
    "       model(Model): Neural network in Keras\n",
    "       layer_size(int): number of neurons to go in layer\n",
    "       need_input(bool): signals if the convolutional layer needs to specify\n",
    "                         the dimensions of the input\n",
    "       kernel_size(tuple): specifies a square matrix to use for kernel dimensions\n",
    "       pool_size(tuple): specifies a square matrix to use in pooling\n",
    "       \n",
    "       Returns: None\n",
    "       \n",
    "    \"\"\"\n",
    "    # set kernel and pool size\n",
    "    if kernel_size is None:\n",
    "        kernel_size = (3, 3)\n",
    "    if pool_size is None:\n",
    "        pool_size = (2, 2)\n",
    "    # specify input dimension for 1st conv layer\n",
    "    if needs_input is True:\n",
    "        conv_layer = Conv2D(layer_size,\n",
    "                            kernel_size=kernel_size,\n",
    "                            activation='relu',\n",
    "                            input_shape=(1024, 1024, 3))\n",
    "\n",
    "    else:\n",
    "        # otherwise all other convolutional layers don't need it\n",
    "        conv_layer = Conv2D(layer_size,\n",
    "                            kernel_size=kernel_size,\n",
    "                            activation='relu')\n",
    "    # add Convolutional layer\n",
    "    model.add(conv_layer)  \n",
    "    # add MaxPooling layer\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))  # no learning params\n",
    "    return None\n",
    "                  \n",
    "    \n",
    "def add_dense_layer(model, layer_size, is_output, drop_rate):\n",
    "    \"\"\"Add a multi-layer perceptron to the model\n",
    "       Will specify 'sigmoid' for the final layer.\n",
    "       \n",
    "       Parameters:\n",
    "       model(Model): Neural network in Keras\n",
    "       layer_size(int): number of neurons to go in layer\n",
    "       is_output(bdool): signals if the MLP is the last layer\n",
    "       drop_rate(float): percentage of connections in Dense layer\n",
    "                       to cut off\n",
    "       \n",
    "       Returns: None\n",
    "       \n",
    "    \"\"\"\n",
    "    # specify activation function\n",
    "    activation = 'relu' if is_output is False else 'sigmoid'\n",
    "    # add MLP\n",
    "    model.add(Dense(layer_size, activation=activation)) \n",
    "    # Add Dropout layer and Batch Normalization\n",
    "    if is_output is False:\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(drop_rate))\n",
    "    return None\n",
    "\n",
    "def compile_model(model, optimizer=None):\n",
    "    \"\"\"Compile the neural network.\n",
    "    \n",
    "       Parameter:\n",
    "       model(keras.Sequential or keras.Model): the model object\n",
    "       optimizer(str): specfies the algoritm used to minimize loss\n",
    "       \n",
    "       Returns: None\n",
    "       \n",
    "    \"\"\"\n",
    "    # set the optimizer\n",
    "    if optimizer is None:\n",
    "        optimizer = 'adam'\n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy',\n",
    "                           tf.keras.metrics.Precision(),\n",
    "                           tf.keras.metrics.Recall()])\n",
    "    return None\n",
    "\n",
    "def define_model(units, conv_layers, dense_layers, dropout):\n",
    "    \"\"\"Define a CNN + MLP model in Keras.\n",
    "    \n",
    "       Parameters:\n",
    "       units(int): number of neurons to go in a layer\n",
    "       conv_layers(int): number of convolutional layers\n",
    "       dense_layers(int): number of MLP\n",
    "       dropout(float): percentage of connections in Dense layer\n",
    "                       to cut off\n",
    "                       \n",
    "       Returns: tf.keras.Sequential: the neural network to train\n",
    "    \n",
    "    \"\"\"\n",
    "    # Instaniate model\n",
    "    model = Sequential()\n",
    "    # Add CNN layers\n",
    "    add_conv_layer(model, units, True)\n",
    "    for l in range(conv_layers - 1):\n",
    "        # add convolutional layers that come after the 1st\n",
    "        add_conv_layer(model, units, False)\n",
    "    # Flatten the data\n",
    "    model.add(Flatten())\n",
    "    # Add MLP Layers\n",
    "    for l in range(dense_layers - 1):\n",
    "        add_dense_layer(model, units, False, dropout)\n",
    "    # add final MLP, for output\n",
    "    add_dense_layer(model, 1, True, dropout)\n",
    "    # Compile Model\n",
    "    compile_model(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, df_training,\n",
    "                df_testing, epochs, \n",
    "                batch_size, callbacks,\n",
    "                steps_per_epoch=None,\n",
    "                val_steps=None):\n",
    "    \"\"\"Train the Keras model using a generator and callback functions.\n",
    "       \n",
    "       Parameters:\n",
    "       model(keras.Sequential or keras.Model): the model object\n",
    "       df_training(pd.DataFrame): subsection of the dataset for training\n",
    "       df_testing(pd.DataFrame): subsection of the dataset for testing\n",
    "       epochs(int): number of forward and back passes for the entire\n",
    "                    dataset through the model\n",
    "       batch_size(int): number of samples the model trains on in one \n",
    "                        batch (small subsection of the training data)\n",
    "       callbacks(List<function>): special Keras functions to improve models\n",
    "       \n",
    "       returns: History.history: a dict containing metrics about model\n",
    "       \n",
    "    \"\"\"\n",
    "    # train the model\n",
    "    history = model.fit_generator(generator=data_gen(df_training, batch_size=batch_size),\n",
    "                                steps_per_epoch=len(df_training['label']) // batch_size,\n",
    "                                epochs=epochs,\n",
    "                                validation_data=data_gen(df_testing, batch_size=batch_size),\n",
    "                                validation_steps=len(df_testing['label']) // batch_size, \n",
    "                                callbacks=callbacks)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zainraza/Downloads/dev/courses/DS/detecting-fires/env/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/zainraza/Downloads/dev/courses/DS/detecting-fires/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/zainraza/Downloads/dev/courses/DS/detecting-fires/env/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/zainraza/Downloads/dev/courses/DS/detecting-fires/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/zainraza/Downloads/dev/courses/DS/detecting-fires/env/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/zainraza/Downloads/dev/courses/DS/detecting-fires/env/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 62s 3s/step - loss: 0.8858 - accuracy: 0.9812 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "WARNING:tensorflow:From /Users/zainraza/Downloads/dev/courses/DS/detecting-fires/env/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 72s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 62s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 63s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 63s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 87s 4s/step - loss: 6.1026e-11 - accuracy: 1.0000 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 873s 36s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 68s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 68s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 75s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 81s 3s/step - loss: 0.1708 - accuracy: 0.9917 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 81s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 90s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 71s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 65s 3s/step - loss: 4.6359e-04 - accuracy: 1.0000 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 65s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 63s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 100s 4s/step - loss: 1.4490 - accuracy: 0.9646 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 99s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 98s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 101s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 102s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "24/24 [==============================] - 111s 5s/step - loss: 1.0770e-12 - accuracy: 1.0000 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 4.1001e-14 - val_accuracy: 1.0000 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 113s 5s/step - loss: 5.3876e-14 - accuracy: 1.0000 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.7559e-14 - val_accuracy: 1.0000 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 114s 5s/step - loss: 3.1342e-14 - accuracy: 1.0000 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.3258e-14 - val_accuracy: 1.0000 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 107s 4s/step - loss: 2.4618e-14 - accuracy: 1.0000 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 1.0881e-14 - val_accuracy: 1.0000 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 109s 5s/step - loss: 2.0272e-14 - accuracy: 1.0000 - precision_5: 0.0000e+00 - recall_5: 0.0000e+00 - val_loss: 9.1331e-15 - val_accuracy: 1.0000 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 103s 4s/step - loss: 0.2360 - accuracy: 0.9875 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 98s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 100s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 101s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 101s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_6: 0.0000e+00 - recall_6: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 149s 6s/step - loss: 2.5329e-27 - accuracy: 1.0000 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1.1932e-20 - val_accuracy: 1.0000 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 145s 6s/step - loss: 2.5329e-27 - accuracy: 1.0000 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1.1932e-20 - val_accuracy: 1.0000 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 147s 6s/step - loss: 2.5329e-27 - accuracy: 1.0000 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1.1932e-20 - val_accuracy: 1.0000 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 140s 6s/step - loss: 2.5329e-27 - accuracy: 1.0000 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1.1932e-20 - val_accuracy: 1.0000 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 146s 6s/step - loss: 2.5329e-27 - accuracy: 1.0000 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 1.1932e-20 - val_accuracy: 1.0000 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 163s 7s/step - loss: 0.9541 - accuracy: 0.9667 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 162s 7s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 168s 7s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 176s 7s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 181s 8s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_8: 0.0000e+00 - recall_8: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 78s 3s/step - loss: 0.6798 - accuracy: 0.9854 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00 - val_loss: 0.6535 - val_accuracy: 1.0000 - val_precision_9: 0.0000e+00 - val_recall_9: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 74s 3s/step - loss: 0.6361 - accuracy: 1.0000 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00 - val_loss: 0.6163 - val_accuracy: 1.0000 - val_precision_9: 0.0000e+00 - val_recall_9: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 78s 3s/step - loss: 0.5970 - accuracy: 1.0000 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00 - val_loss: 0.5791 - val_accuracy: 1.0000 - val_precision_9: 0.0000e+00 - val_recall_9: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 71s 3s/step - loss: 0.5577 - accuracy: 1.0000 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00 - val_loss: 0.5408 - val_accuracy: 1.0000 - val_precision_9: 0.0000e+00 - val_recall_9: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 71s 3s/step - loss: 0.5202 - accuracy: 1.0000 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00 - val_loss: 0.5021 - val_accuracy: 1.0000 - val_precision_9: 0.0000e+00 - val_recall_9: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 125s 5s/step - loss: 0.7660 - accuracy: 0.3521 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 3.3938 - val_accuracy: 0.0500 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 107s 4s/step - loss: 0.7110 - accuracy: 0.4271 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 2.1975 - val_accuracy: 0.0500 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 97s 4s/step - loss: 0.6545 - accuracy: 0.5625 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 1.0859 - val_accuracy: 0.1000 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 86s 4s/step - loss: 0.6175 - accuracy: 0.6708 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 0.7147 - val_accuracy: 0.3500 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 84s 4s/step - loss: 0.5649 - accuracy: 0.7937 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 0.4170 - val_accuracy: 1.0000 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 83s 3s/step - loss: 0.7795 - accuracy: 0.5125 - precision_11: 0.0000e+00 - recall_11: 0.0000e+00 - val_loss: 0.0489 - val_accuracy: 1.0000 - val_precision_11: 0.0000e+00 - val_recall_11: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 71s 3s/step - loss: 0.7200 - accuracy: 0.4479 - precision_11: 0.0000e+00 - recall_11: 0.0000e+00 - val_loss: 0.0857 - val_accuracy: 1.0000 - val_precision_11: 0.0000e+00 - val_recall_11: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 76s 3s/step - loss: 0.6716 - accuracy: 0.6146 - precision_11: 0.0000e+00 - recall_11: 0.0000e+00 - val_loss: 0.1688 - val_accuracy: 1.0000 - val_precision_11: 0.0000e+00 - val_recall_11: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "24/24 [==============================] - 75s 3s/step - loss: 0.6369 - accuracy: 0.6438 - precision_11: 0.0000e+00 - recall_11: 0.0000e+00 - val_loss: 0.3559 - val_accuracy: 0.9500 - val_precision_11: 0.0000e+00 - val_recall_11: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 74s 3s/step - loss: 0.5971 - accuracy: 0.7500 - precision_11: 0.0000e+00 - recall_11: 0.0000e+00 - val_loss: 0.3577 - val_accuracy: 0.9500 - val_precision_11: 0.0000e+00 - val_recall_11: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 67s 3s/step - loss: 0.7814 - accuracy: 0.3979 - precision_12: 0.0000e+00 - recall_12: 0.0000e+00 - val_loss: 0.4248 - val_accuracy: 0.7500 - val_precision_12: 0.0000e+00 - val_recall_12: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 64s 3s/step - loss: 0.7308 - accuracy: 0.4187 - precision_12: 0.0000e+00 - recall_12: 0.0000e+00 - val_loss: 0.5950 - val_accuracy: 0.6500 - val_precision_12: 0.0000e+00 - val_recall_12: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 65s 3s/step - loss: 0.6413 - accuracy: 0.5271 - precision_12: 0.0000e+00 - recall_12: 0.0000e+00 - val_loss: 0.6571 - val_accuracy: 0.6500 - val_precision_12: 0.0000e+00 - val_recall_12: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 69s 3s/step - loss: 0.5755 - accuracy: 0.7125 - precision_12: 0.0000e+00 - recall_12: 0.0000e+00 - val_loss: 0.5744 - val_accuracy: 0.8500 - val_precision_12: 0.0000e+00 - val_recall_12: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 72s 3s/step - loss: 0.5404 - accuracy: 0.8750 - precision_12: 0.0000e+00 - recall_12: 0.0000e+00 - val_loss: 0.5530 - val_accuracy: 0.8500 - val_precision_12: 0.0000e+00 - val_recall_12: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 96s 4s/step - loss: 0.8362 - accuracy: 0.5021 - precision_13: 0.0000e+00 - recall_13: 0.0000e+00 - val_loss: 7.9876e-04 - val_accuracy: 1.0000 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.6878 - accuracy: 0.5792 - precision_13: 0.0000e+00 - recall_13: 0.0000e+00 - val_loss: 0.1214 - val_accuracy: 1.0000 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 90s 4s/step - loss: 0.6110 - accuracy: 0.7375 - precision_13: 0.0000e+00 - recall_13: 0.0000e+00 - val_loss: 0.2291 - val_accuracy: 1.0000 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 83s 3s/step - loss: 0.5553 - accuracy: 0.8250 - precision_13: 0.0000e+00 - recall_13: 0.0000e+00 - val_loss: 0.2225 - val_accuracy: 1.0000 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 87s 4s/step - loss: 0.5374 - accuracy: 0.8542 - precision_13: 0.0000e+00 - recall_13: 0.0000e+00 - val_loss: 0.3717 - val_accuracy: 1.0000 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 94s 4s/step - loss: 0.6979 - accuracy: 0.5542 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.2303 - val_accuracy: 1.0000 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 104s 4s/step - loss: 0.6472 - accuracy: 0.7000 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.4248 - val_accuracy: 1.0000 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 102s 4s/step - loss: 0.5917 - accuracy: 0.9042 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.4715 - val_accuracy: 1.0000 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 94s 4s/step - loss: 0.5453 - accuracy: 0.9563 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.4479 - val_accuracy: 1.0000 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.5018 - accuracy: 0.9667 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_loss: 0.4173 - val_accuracy: 1.0000 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 105s 4s/step - loss: 0.8518 - accuracy: 0.4563 - precision_15: 0.0000e+00 - recall_15: 0.0000e+00 - val_loss: 2.2416 - val_accuracy: 0.0000e+00 - val_precision_15: 0.0000e+00 - val_recall_15: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 94s 4s/step - loss: 0.6867 - accuracy: 0.6125 - precision_15: 0.0000e+00 - recall_15: 0.0000e+00 - val_loss: 0.9189 - val_accuracy: 0.1500 - val_precision_15: 0.0000e+00 - val_recall_15: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 90s 4s/step - loss: 0.5796 - accuracy: 0.7583 - precision_15: 0.0000e+00 - recall_15: 0.0000e+00 - val_loss: 0.6090 - val_accuracy: 0.8000 - val_precision_15: 0.0000e+00 - val_recall_15: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 89s 4s/step - loss: 0.5186 - accuracy: 0.8729 - precision_15: 0.0000e+00 - recall_15: 0.0000e+00 - val_loss: 0.5069 - val_accuracy: 1.0000 - val_precision_15: 0.0000e+00 - val_recall_15: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 91s 4s/step - loss: 0.4424 - accuracy: 0.9646 - precision_15: 0.0000e+00 - recall_15: 0.0000e+00 - val_loss: 0.3400 - val_accuracy: 1.0000 - val_precision_15: 0.0000e+00 - val_recall_15: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 122s 5s/step - loss: 0.9518 - accuracy: 0.6229 - precision_16: 0.0000e+00 - recall_16: 0.0000e+00 - val_loss: 0.8659 - val_accuracy: 0.5500 - val_precision_16: 0.0000e+00 - val_recall_16: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 123s 5s/step - loss: 0.7376 - accuracy: 0.7292 - precision_16: 0.0000e+00 - recall_16: 0.0000e+00 - val_loss: 1.3631 - val_accuracy: 0.0500 - val_precision_16: 0.0000e+00 - val_recall_16: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 123s 5s/step - loss: 0.5725 - accuracy: 0.7979 - precision_16: 0.0000e+00 - recall_16: 0.0000e+00 - val_loss: 1.0472 - val_accuracy: 0.0000e+00 - val_precision_16: 0.0000e+00 - val_recall_16: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 123s 5s/step - loss: 0.4985 - accuracy: 0.8708 - precision_16: 0.0000e+00 - recall_16: 0.0000e+00 - val_loss: 0.8262 - val_accuracy: 0.2000 - val_precision_16: 0.0000e+00 - val_recall_16: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 115s 5s/step - loss: 0.4391 - accuracy: 0.9271 - precision_16: 0.0000e+00 - recall_16: 0.0000e+00 - val_loss: 0.5419 - val_accuracy: 0.9000 - val_precision_16: 0.0000e+00 - val_recall_16: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 118s 5s/step - loss: 0.7395 - accuracy: 0.5375 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00 - val_loss: 0.6674 - val_accuracy: 0.6000 - val_precision_17: 0.0000e+00 - val_recall_17: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 120s 5s/step - loss: 0.6351 - accuracy: 0.6771 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00 - val_loss: 0.4394 - val_accuracy: 1.0000 - val_precision_17: 0.0000e+00 - val_recall_17: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 126s 5s/step - loss: 0.5812 - accuracy: 0.7979 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00 - val_loss: 0.6297 - val_accuracy: 0.7000 - val_precision_17: 0.0000e+00 - val_recall_17: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 25461s 1061s/step - loss: 0.5293 - accuracy: 0.8396 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00 - val_loss: 0.9051 - val_accuracy: 0.0500 - val_precision_17: 0.0000e+00 - val_recall_17: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 14799s 617s/step - loss: 0.4715 - accuracy: 0.9021 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00 - val_loss: 0.7326 - val_accuracy: 0.3500 - val_precision_17: 0.0000e+00 - val_recall_17: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 1558s 65s/step - loss: 0.7239 - accuracy: 0.3646 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_loss: 0.7090 - val_accuracy: 0.1000 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "24/24 [==============================] - 51s 2s/step - loss: 0.6801 - accuracy: 0.4417 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_loss: 0.6623 - val_accuracy: 0.9500 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 51s 2s/step - loss: 0.6541 - accuracy: 0.6729 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_loss: 0.6362 - val_accuracy: 0.9500 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 53s 2s/step - loss: 0.6331 - accuracy: 0.7917 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_loss: 0.6046 - val_accuracy: 1.0000 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 58s 2s/step - loss: 0.6033 - accuracy: 0.8271 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_loss: 0.5750 - val_accuracy: 1.0000 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 77s 3s/step - loss: 0.9211 - accuracy: 0.5771 - precision_19: 0.0000e+00 - recall_19: 0.0000e+00 - val_loss: 1.3236 - val_accuracy: 0.0000e+00 - val_precision_19: 0.0000e+00 - val_recall_19: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 73s 3s/step - loss: 0.8512 - accuracy: 0.4792 - precision_19: 0.0000e+00 - recall_19: 0.0000e+00 - val_loss: 4.6538 - val_accuracy: 0.0000e+00 - val_precision_19: 0.0000e+00 - val_recall_19: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 73s 3s/step - loss: 0.7474 - accuracy: 0.5021 - precision_19: 0.0000e+00 - recall_19: 0.0000e+00 - val_loss: 2.5246 - val_accuracy: 0.0000e+00 - val_precision_19: 0.0000e+00 - val_recall_19: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 77s 3s/step - loss: 0.6688 - accuracy: 0.6146 - precision_19: 0.0000e+00 - recall_19: 0.0000e+00 - val_loss: 1.5252 - val_accuracy: 0.1500 - val_precision_19: 0.0000e+00 - val_recall_19: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 77s 3s/step - loss: 0.6684 - accuracy: 0.6958 - precision_19: 0.0000e+00 - recall_19: 0.0000e+00 - val_loss: 0.8404 - val_accuracy: 0.3500 - val_precision_19: 0.0000e+00 - val_recall_19: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 80s 3s/step - loss: 0.8448 - accuracy: 0.6271 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00 - val_loss: 5.6749 - val_accuracy: 0.0000e+00 - val_precision_20: 0.0000e+00 - val_recall_20: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 74s 3s/step - loss: 0.7499 - accuracy: 0.5896 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00 - val_loss: 3.1859 - val_accuracy: 0.0000e+00 - val_precision_20: 0.0000e+00 - val_recall_20: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 75s 3s/step - loss: 0.7016 - accuracy: 0.6313 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00 - val_loss: 2.0362 - val_accuracy: 0.0000e+00 - val_precision_20: 0.0000e+00 - val_recall_20: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 75s 3s/step - loss: 0.6491 - accuracy: 0.6646 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00 - val_loss: 2.1041 - val_accuracy: 0.0500 - val_precision_20: 0.0000e+00 - val_recall_20: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 75s 3s/step - loss: 0.6004 - accuracy: 0.6812 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00 - val_loss: 1.8056 - val_accuracy: 0.1000 - val_precision_20: 0.0000e+00 - val_recall_20: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 69s 3s/step - loss: 0.9363 - accuracy: 0.5396 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00 - val_loss: 0.4555 - val_accuracy: 0.8000 - val_precision_21: 0.0000e+00 - val_recall_21: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 66s 3s/step - loss: 0.7899 - accuracy: 0.6167 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00 - val_loss: 0.8079 - val_accuracy: 0.4500 - val_precision_21: 0.0000e+00 - val_recall_21: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 68s 3s/step - loss: 0.7066 - accuracy: 0.6542 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00 - val_loss: 0.5362 - val_accuracy: 0.8000 - val_precision_21: 0.0000e+00 - val_recall_21: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 69s 3s/step - loss: 0.6635 - accuracy: 0.6833 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00 - val_loss: 0.7508 - val_accuracy: 0.5000 - val_precision_21: 0.0000e+00 - val_recall_21: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 65s 3s/step - loss: 0.6281 - accuracy: 0.7229 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00 - val_loss: 0.8166 - val_accuracy: 0.6500 - val_precision_21: 0.0000e+00 - val_recall_21: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 87s 4s/step - loss: 0.7416 - accuracy: 0.5792 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00 - val_loss: 0.6575 - val_accuracy: 1.0000 - val_precision_22: 0.0000e+00 - val_recall_22: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 87s 4s/step - loss: 0.6222 - accuracy: 0.7417 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00 - val_loss: 0.5960 - val_accuracy: 1.0000 - val_precision_22: 0.0000e+00 - val_recall_22: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 96s 4s/step - loss: 0.5829 - accuracy: 0.9458 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00 - val_loss: 0.5472 - val_accuracy: 1.0000 - val_precision_22: 0.0000e+00 - val_recall_22: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 91s 4s/step - loss: 0.5365 - accuracy: 1.0000 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00 - val_loss: 0.5011 - val_accuracy: 1.0000 - val_precision_22: 0.0000e+00 - val_recall_22: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 85s 4s/step - loss: 0.4949 - accuracy: 1.0000 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00 - val_loss: 0.4555 - val_accuracy: 1.0000 - val_precision_22: 0.0000e+00 - val_recall_22: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 94s 4s/step - loss: 0.8336 - accuracy: 0.6167 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00 - val_loss: 2.5159 - val_accuracy: 0.0500 - val_precision_23: 0.0000e+00 - val_recall_23: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 90s 4s/step - loss: 0.7348 - accuracy: 0.6208 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00 - val_loss: 1.7670 - val_accuracy: 0.0000e+00 - val_precision_23: 0.0000e+00 - val_recall_23: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 88s 4s/step - loss: 0.6749 - accuracy: 0.6375 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00 - val_loss: 818.5957 - val_accuracy: 0.0000e+00 - val_precision_23: 0.0000e+00 - val_recall_23: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.6180 - accuracy: 0.7125 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00 - val_loss: 3.1138 - val_accuracy: 0.0000e+00 - val_precision_23: 0.0000e+00 - val_recall_23: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 94s 4s/step - loss: 0.5704 - accuracy: 0.7833 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00 - val_loss: 1.6497 - val_accuracy: 0.0000e+00 - val_precision_23: 0.0000e+00 - val_recall_23: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 101s 4s/step - loss: 0.7765 - accuracy: 0.5458 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00 - val_loss: 1.0637 - val_accuracy: 0.2500 - val_precision_24: 0.0000e+00 - val_recall_24: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 88s 4s/step - loss: 0.6832 - accuracy: 0.5958 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00 - val_loss: 0.7531 - val_accuracy: 0.4000 - val_precision_24: 0.0000e+00 - val_recall_24: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 89s 4s/step - loss: 0.6307 - accuracy: 0.6938 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00 - val_loss: 0.5569 - val_accuracy: 0.8500 - val_precision_24: 0.0000e+00 - val_recall_24: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 100s 4s/step - loss: 0.5658 - accuracy: 0.7750 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00 - val_loss: 0.5048 - val_accuracy: 0.9500 - val_precision_24: 0.0000e+00 - val_recall_24: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "24/24 [==============================] - 91s 4s/step - loss: 0.5033 - accuracy: 0.8604 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00 - val_loss: 0.4106 - val_accuracy: 1.0000 - val_precision_24: 0.0000e+00 - val_recall_24: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 117s 5s/step - loss: 0.8622 - accuracy: 0.5188 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00 - val_loss: 3.2550 - val_accuracy: 0.0000e+00 - val_precision_25: 0.0000e+00 - val_recall_25: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 123s 5s/step - loss: 0.7150 - accuracy: 0.6417 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00 - val_loss: 1.7079 - val_accuracy: 0.0000e+00 - val_precision_25: 0.0000e+00 - val_recall_25: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 131s 5s/step - loss: 0.6198 - accuracy: 0.6896 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00 - val_loss: 1.4919 - val_accuracy: 0.1000 - val_precision_25: 0.0000e+00 - val_recall_25: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 138s 6s/step - loss: 0.5597 - accuracy: 0.7563 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00 - val_loss: 0.9355 - val_accuracy: 0.2000 - val_precision_25: 0.0000e+00 - val_recall_25: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 121s 5s/step - loss: 0.4957 - accuracy: 0.8125 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00 - val_loss: 0.6669 - val_accuracy: 0.4500 - val_precision_25: 0.0000e+00 - val_recall_25: 0.0000e+00\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 131s 5s/step - loss: 0.8272 - accuracy: 0.5646 - precision_26: 0.0000e+00 - recall_26: 0.0000e+00 - val_loss: 1.1338 - val_accuracy: 0.2000 - val_precision_26: 0.0000e+00 - val_recall_26: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 140s 6s/step - loss: 0.7152 - accuracy: 0.5896 - precision_26: 0.0000e+00 - recall_26: 0.0000e+00 - val_loss: 1.1048 - val_accuracy: 0.2500 - val_precision_26: 0.0000e+00 - val_recall_26: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 139s 6s/step - loss: 0.6240 - accuracy: 0.6771 - precision_26: 0.0000e+00 - recall_26: 0.0000e+00 - val_loss: 0.7932 - val_accuracy: 0.3500 - val_precision_26: 0.0000e+00 - val_recall_26: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 139s 6s/step - loss: 0.5318 - accuracy: 0.7625 - precision_26: 0.0000e+00 - recall_26: 0.0000e+00 - val_loss: 0.6038 - val_accuracy: 0.7000 - val_precision_26: 0.0000e+00 - val_recall_26: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 133s 6s/step - loss: 0.5106 - accuracy: 0.7750 - precision_26: 0.0000e+00 - recall_26: 0.0000e+00 - val_loss: 0.5000 - val_accuracy: 0.8000 - val_precision_26: 0.0000e+00 - val_recall_26: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Choices for the Model Architecture - values arbitrary\n",
    "dense_layers = [1, 2, 3]\n",
    "layer_sizes = [4, 8, 16]\n",
    "conv_layers = [1, 2, 3]\n",
    "\n",
    "# try different combinations!\n",
    "# These for loops come from https://youtu.be/lV09_8432VA\n",
    "for dense_layer in dense_layers:\n",
    "    for size in layer_sizes:\n",
    "        for conv in conv_layers:\n",
    "            # name the combo\n",
    "            NAME = (\n",
    "                f'{conv}-conv-{size}-nodes' +\n",
    "                f'-{dense_layer}-dense_layers' + \n",
    "                f'-{int(time.time())}'\n",
    "            )\n",
    "            # Instantiate TensorBoard to visualize model performance\n",
    "            tensorboard = TensorBoard(log_dir=f'./Graph/{NAME}')\n",
    "            # Define Model\n",
    "            model = define_model(size, conv, dense_layer, 0.2)\n",
    "            # Train the Model (using a generator!)\n",
    "            epochs, batch_size = 5, 20\n",
    "            history = train_model(model, df_train, df_test, epochs, \n",
    "                                  batch_size, [tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Conclusion: What's the Best Architecture for the Model?**\n",
    "\n",
    "After training the different combinations above and looking through the [logs](Graph/) returned by Tensorboard, the best model archtecture has been determined to be:\n",
    "\n",
    "- 3 Conv2D Layers\n",
    "- 1 Dense Layer\n",
    "- 4 Neurons in each Layer\n",
    "- Dropout Rate of 20%\n",
    "- 5 epochs\n",
    "- 20 samples per Batch\n",
    "\n",
    "This model had the following metrics, which was the best of any of the other models:\n",
    "\n",
    "- Validation Accuracy: 100%\n",
    "- Validation Loss: 4.51e31%\n",
    "- Validation Precision: 96.25%\n",
    "- Validation Recall: 95.09%\n",
    "- F1-Score: 0.9567\n",
    "\n",
    "Although the accuracy of 100% is a little concerning, it may be possible to prevent overfitting by increase the drop out rate to 30%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Finding Optimal Hyperparameters\n",
    "\n",
    "Now, we'll find the optimal values for the hyperparameters using hyperas...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import seaborn as sns\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Flatten, BatchNormalization\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import SGD\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.initializers import RandomNormal\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping, TensorBoard\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import time\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from PIL import Image\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing.image import img_to_array\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import util\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import model_from_json\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.utils import resample\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'kernel_size': hp.choice('kernel_size', [(1, 1),(2, 2),(3, 3)]),\n",
      "        'kernel_size_1': hp.choice('kernel_size_1', [(1, 1),(2, 2),(3, 3)]),\n",
      "        'kernel_size_2': hp.choice('kernel_size_2', [(1, 1),(2, 2),(3, 3)]),\n",
      "        'kernel_size_3': hp.choice('kernel_size_3', [(1, 1),(2, 2),(3, 3)]),\n",
      "        'kernel_size_4': hp.choice('kernel_size_4', [(1, 1),(2, 2),(3, 3)]),\n",
      "        'kernel_size_5': hp.choice('kernel_size_5', [(1, 1),(2, 2),(3, 3)]),\n",
      "        'activation': hp.choice('activation', ['sigmoid', 'relu']),\n",
      "        'optimizer': hp.choice('optimizer', \n",
      "                          [keras.optimizers.Adadelta(),\n",
      "                          'sgd', 'adam', 'rmsprop']   \n",
      "                           ),\n",
      "        'batch_size': hp.choice('batch_size', [10, 20, 40]),\n",
      "        'epochs': hp.choice('epochs', [3, 5, 7]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: \"\"\"Data providing function (will later use for Hyperas).\"\"\"\n",
      "  3: df = pd.read_csv('Fire-Detection-Image-Dataset/fires.csv')\n",
      "  4: selector = np.random.rand(len(df)) < 0.75\n",
      "  5: df_train, df_test = df[selector], df[~selector]\n",
      "  6: print(f\"Number of Training Samples: {len(df_train)}\")\n",
      "  7: print(f\"Number of Testing Samples: {len(df_test)}\")\n",
      "  8: \n",
      "  9: \n",
      " 10: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \"\"\"Returns a dictionary with the results of the best model.\"\"\"\n",
      "   4:     # define known parameters\n",
      "   5:     layer_size = 4\n",
      "   6:     # Instaniate model\n",
      "   7:     model = Sequential()\n",
      "   8:     # Instantiate TensorBoard to visualize model performance\n",
      "   9:     tensorboard = TensorBoard(log_dir='./Graph')\n",
      "  10:     # Add 3 CNN layers\n",
      "  11:     model.add(Conv2D(layer_size, kernel_size=space['kernel_size'],\n",
      "  12:                      activation='relu',\n",
      "  13:                      input_shape=(1024, 1024, 3)))\n",
      "  14:     model.add(MaxPooling2D(pool_size=space['kernel_size_1']))\n",
      "  15:     model.add(Conv2D(layer_size,\n",
      "  16:                      kernel_size=space['kernel_size_2'],\n",
      "  17:                      activation='relu'))\n",
      "  18:     model.add(MaxPooling2D(pool_size=space['kernel_size_3']))\n",
      "  19:     model.add(Conv2D(layer_size,\n",
      "  20:                      kernel_size=space['kernel_size_4'],\n",
      "  21:                      activation='relu'))\n",
      "  22:     model.add(MaxPooling2D(pool_size=space['kernel_size_5']))\n",
      "  23:     # Flatten the data\n",
      "  24:     model.add(Flatten())\n",
      "  25:     # Add 1 MLP Layer\n",
      "  26:     model.add(Dense(1, activation=space['activation']))\n",
      "  27:     # Compile Model\n",
      "  28:     model.compile(loss=keras.losses.binary_crossentropy,\n",
      "  29:                   optimizer=\n",
      "  30:                       space['optimizer'],\n",
      "  31:                   metrics=['accuracy',\n",
      "  32:                            tf.keras.metrics.Precision(),\n",
      "  33:                            tf.keras.metrics.Recall()])\n",
      "  34:     # Train Model   \n",
      "  35:     batch_size=space['batch_size']\n",
      "  36:     history = model.fit_generator(generator=util.data_gen(df_train, batch_size=batch_size),\n",
      "  37:                                 steps_per_epoch=len(df_train['label']) // batch_size,\n",
      "  38:                                 epochs=space['epochs'],\n",
      "  39:                                 validation_data=util.data_gen(df_test, batch_size=batch_size),\n",
      "  40:                                 validation_steps=len(df_test['label']) // batch_size, \n",
      "  41:                                 callbacks=[tensorboard])\n",
      "  42:     \n",
      "  43:     # Get Optimized results\n",
      "  44:     # get the highest validation metrics of the training epochs\n",
      "  45:     val_loss = np.amax(history.history['val_loss'])\n",
      "  46:     print(f'Best validation acc of epoch: {(1-val_loss)}')\n",
      "  47:     return {\n",
      "  48:         'loss': val_loss,\n",
      "  49:         'accuracy': 1-val_loss,\n",
      "  50:         'status': STATUS_OK,\n",
      "  51:         'model': model\n",
      "  52:     }\n",
      "  53: \n",
      "Number of Training Samples: 479\n",
      "Number of Testing Samples: 172\n",
      "Epoch 1/7                                            \n",
      " 1/11 [=>............................]               \n",
      " - ETA: 1:01 - loss: 36.3025 - accuracy: 0.0000e+00 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 2/11 [====>.........................]               \n",
      " - ETA: 45s - loss: 18.1513 - accuracy: 0.5000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00     \n",
      "                                                     \n",
      " 3/11 [=======>......................]               \n",
      " - ETA: 39s - loss: 12.1008 - accuracy: 0.6667 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                     \n",
      " 4/11 [=========>....................]               \n",
      " - ETA: 33s - loss: 9.0756 - accuracy: 0.7500 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00 \n",
      "                                                    \n",
      " 5/11 [============>.................]               \n",
      " - ETA: 29s - loss: 7.2605 - accuracy: 0.8000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 6/11 [===============>..............]               \n",
      " - ETA: 24s - loss: 6.0504 - accuracy: 0.8333 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 7/11 [==================>...........]               \n",
      " - ETA: 19s - loss: 5.1861 - accuracy: 0.8571 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 8/11 [====================>.........]               \n",
      " - ETA: 14s - loss: 4.5378 - accuracy: 0.8750 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 9/11 [=======================>......]               \n",
      " - ETA: 9s - loss: 4.0336 - accuracy: 0.8889 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00 \n",
      "                                                     \n",
      "10/11 [==========================>...]               \n",
      " - ETA: 4s - loss: 3.6303 - accuracy: 0.9000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                     \n",
      "11/11 [==============================]               \n",
      " - 62s 6s/step - loss: 3.3002 - accuracy: 0.9091 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_35: 0.0000e+00 - val_recall_35: 0.0000e+00\n",
      "\n",
      "Epoch 2/7                                            \n",
      " 1/11 [=>............................]               \n",
      " - ETA: 46s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 2/11 [====>.........................]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - ETA: 39s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 3/11 [=======>......................]               \n",
      " - ETA: 34s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 4/11 [=========>....................]               \n",
      " - ETA: 30s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 5/11 [============>.................]               \n",
      " - ETA: 27s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 6/11 [===============>..............]               \n",
      " - ETA: 23s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 7/11 [==================>...........]               \n",
      " - ETA: 19s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 8/11 [====================>.........]               \n",
      " - ETA: 14s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 9/11 [=======================>......]               \n",
      " - ETA: 9s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00 \n",
      "                                                     \n",
      "10/11 [==========================>...]               \n",
      " - ETA: 5s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                     \n",
      "11/11 [==============================]               \n",
      " - 64s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_35: 0.0000e+00 - val_recall_35: 0.0000e+00\n",
      "\n",
      "Epoch 3/7                                            \n",
      " 1/11 [=>............................]               \n",
      " - ETA: 46s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 2/11 [====>.........................]               \n",
      " - ETA: 41s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 3/11 [=======>......................]               \n",
      " - ETA: 38s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 4/11 [=========>....................]               \n",
      " - ETA: 37s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 5/11 [============>.................]               \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 6/11 [===============>..............]               \n",
      " - ETA: 26s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 7/11 [==================>...........]               \n",
      " - ETA: 21s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 8/11 [====================>.........]               \n",
      " - ETA: 15s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 9/11 [=======================>......]               \n",
      " - ETA: 10s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      "10/11 [==========================>...]               \n",
      " - ETA: 5s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00 \n",
      "                                                     \n",
      "11/11 [==============================]               \n",
      " - 65s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_35: 0.0000e+00 - val_recall_35: 0.0000e+00\n",
      "\n",
      "Epoch 4/7                                            \n",
      " 1/11 [=>............................]               \n",
      " - ETA: 47s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 2/11 [====>.........................]               \n",
      " - ETA: 41s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 3/11 [=======>......................]               \n",
      " - ETA: 37s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 4/11 [=========>....................]               \n",
      " - ETA: 33s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 5/11 [============>.................]               \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 6/11 [===============>..............]               \n",
      " - ETA: 29s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 7/11 [==================>...........]               \n",
      " - ETA: 25s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 8/11 [====================>.........]               \n",
      " - ETA: 21s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 9/11 [=======================>......]               \n",
      " - ETA: 14s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      "10/11 [==========================>...]               \n",
      " - ETA: 7s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00 \n",
      "                                                     \n",
      "11/11 [==============================]               \n",
      " - 87s 8s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_35: 0.0000e+00 - val_recall_35: 0.0000e+00\n",
      "\n",
      "Epoch 5/7                                            \n",
      " 1/11 [=>............................]               \n",
      " - ETA: 55s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 2/11 [====>.........................]               \n",
      " - ETA: 48s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 3/11 [=======>......................]               \n",
      " - ETA: 43s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 4/11 [=========>....................]               \n",
      " - ETA: 37s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 5/11 [============>.................]               \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 6/11 [===============>..............]               \n",
      " - ETA: 26s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/11 [==================>...........]               \n",
      " - ETA: 21s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 8/11 [====================>.........]               \n",
      " - ETA: 15s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 9/11 [=======================>......]               \n",
      " - ETA: 10s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      "10/11 [==========================>...]               \n",
      " - ETA: 5s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00 \n",
      "                                                     \n",
      "11/11 [==============================]               \n",
      " - 65s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_35: 0.0000e+00 - val_recall_35: 0.0000e+00\n",
      "\n",
      "Epoch 6/7                                            \n",
      " 1/11 [=>............................]               \n",
      " - ETA: 58s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 2/11 [====>.........................]               \n",
      " - ETA: 55s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 3/11 [=======>......................]               \n",
      " - ETA: 51s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 4/11 [=========>....................]               \n",
      " - ETA: 44s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 5/11 [============>.................]               \n",
      " - ETA: 38s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 6/11 [===============>..............]               \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 7/11 [==================>...........]               \n",
      " - ETA: 25s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 8/11 [====================>.........]               \n",
      " - ETA: 18s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 9/11 [=======================>......]               \n",
      " - ETA: 12s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      "10/11 [==========================>...]               \n",
      " - ETA: 6s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00 \n",
      "                                                     \n",
      "11/11 [==============================]               \n",
      " - 74s 7s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_35: 0.0000e+00 - val_recall_35: 0.0000e+00\n",
      "\n",
      "Epoch 7/7                                            \n",
      " 1/11 [=>............................]               \n",
      " - ETA: 55s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 2/11 [====>.........................]               \n",
      " - ETA: 52s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 3/11 [=======>......................]               \n",
      " - ETA: 45s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 4/11 [=========>....................]               \n",
      " - ETA: 37s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 5/11 [============>.................]               \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 6/11 [===============>..............]               \n",
      " - ETA: 25s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 7/11 [==================>...........]               \n",
      " - ETA: 20s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 8/11 [====================>.........]               \n",
      " - ETA: 14s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                    \n",
      " 9/11 [=======================>......]               \n",
      " - ETA: 9s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00 \n",
      "                                                     \n",
      "10/11 [==========================>...]               \n",
      " - ETA: 4s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "                                                     \n",
      "11/11 [==============================]               \n",
      " - 68s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_35: 0.0000e+00 - val_recall_35: 0.0000e+00\n",
      "\n",
      "Best validation acc of epoch: 1.0                    \n",
      "Epoch 1/7                                                        \n",
      " 1/11 [=>............................]                           \n",
      " - ETA: 2:37 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 2/11 [====>.........................]                           \n",
      " - ETA: 2:08 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 3/11 [=======>......................]                           \n",
      " - ETA: 1:47 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 4/11 [=========>....................]                           \n",
      " - ETA: 1:30 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 5/11 [============>.................]                           \n",
      " - ETA: 1:14 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 6/11 [===============>..............]                           \n",
      " - ETA: 1:00 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 7/11 [==================>...........]                           \n",
      " - ETA: 50s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 \n",
      "                                                                \n",
      " 8/11 [====================>.........]                           \n",
      " - ETA: 38s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      " 9/11 [=======================>......]                           \n",
      " - ETA: 26s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      "10/11 [==========================>...]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - ETA: 12s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      "11/11 [==============================]                           \n",
      " - 155s 14s/step - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_36: 0.0000e+00 - val_recall_36: 0.0000e+00\n",
      "\n",
      "Epoch 2/7                                                        \n",
      " 1/11 [=>............................]                           \n",
      " - ETA: 2:06 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 2/11 [====>.........................]                           \n",
      " - ETA: 1:43 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 3/11 [=======>......................]                           \n",
      " - ETA: 1:29 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 4/11 [=========>....................]                           \n",
      " - ETA: 1:23 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 5/11 [============>.................]                           \n",
      " - ETA: 1:13 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 6/11 [===============>..............]                           \n",
      " - ETA: 1:02 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 7/11 [==================>...........]                           \n",
      " - ETA: 51s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 \n",
      "                                                                \n",
      " 8/11 [====================>.........]                           \n",
      " - ETA: 38s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      " 9/11 [=======================>......]                           \n",
      " - ETA: 25s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      "10/11 [==========================>...]                           \n",
      " - ETA: 12s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      "11/11 [==============================]                           \n",
      " - 146s 13s/step - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_36: 0.0000e+00 - val_recall_36: 0.0000e+00\n",
      "\n",
      "Epoch 3/7                                                        \n",
      " 1/11 [=>............................]                           \n",
      " - ETA: 1:49 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 2/11 [====>.........................]                           \n",
      " - ETA: 1:48 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 3/11 [=======>......................]                           \n",
      " - ETA: 1:37 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 4/11 [=========>....................]                           \n",
      " - ETA: 1:29 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 5/11 [============>.................]                           \n",
      " - ETA: 1:16 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 6/11 [===============>..............]                           \n",
      " - ETA: 1:02 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 7/11 [==================>...........]                           \n",
      " - ETA: 48s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 \n",
      "                                                                \n",
      " 8/11 [====================>.........]                           \n",
      " - ETA: 35s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      " 9/11 [=======================>......]                           \n",
      " - ETA: 22s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      "10/11 [==========================>...]                           \n",
      " - ETA: 10s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      "11/11 [==============================]                           \n",
      " - 128s 12s/step - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_36: 0.0000e+00 - val_recall_36: 0.0000e+00\n",
      "\n",
      "Epoch 4/7                                                        \n",
      " 1/11 [=>............................]                           \n",
      " - ETA: 1:58 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 2/11 [====>.........................]                           \n",
      " - ETA: 1:55 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 3/11 [=======>......................]                           \n",
      " - ETA: 1:41 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 4/11 [=========>....................]                           \n",
      " - ETA: 1:26 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 5/11 [============>.................]                           \n",
      " - ETA: 1:13 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 6/11 [===============>..............]                           \n",
      " - ETA: 58s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 \n",
      "                                                                \n",
      " 7/11 [==================>...........]                           \n",
      " - ETA: 45s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      " 8/11 [====================>.........]                           \n",
      " - ETA: 32s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      " 9/11 [=======================>......]                           \n",
      " - ETA: 21s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      "10/11 [==========================>...]                           \n",
      " - ETA: 10s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      "11/11 [==============================]                           \n",
      " - 133s 12s/step - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_36: 0.0000e+00 - val_recall_36: 0.0000e+00\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/7                                                        \n",
      " 1/11 [=>............................]                           \n",
      " - ETA: 2:57 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 2/11 [====>.........................]                           \n",
      " - ETA: 2:20 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 3/11 [=======>......................]                           \n",
      " - ETA: 1:52 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 4/11 [=========>....................]                           \n",
      " - ETA: 1:30 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 5/11 [============>.................]                           \n",
      " - ETA: 1:12 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 6/11 [===============>..............]                           \n",
      " - ETA: 58s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 \n",
      "                                                                \n",
      " 7/11 [==================>...........]                           \n",
      " - ETA: 45s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      " 8/11 [====================>.........]                           \n",
      " - ETA: 33s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      " 9/11 [=======================>......]                           \n",
      " - ETA: 22s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      "10/11 [==========================>...]                           \n",
      " - ETA: 10s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      "11/11 [==============================]                           \n",
      " - 140s 13s/step - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_36: 0.0000e+00 - val_recall_36: 0.0000e+00\n",
      "\n",
      "Epoch 6/7                                                        \n",
      " 1/11 [=>............................]                           \n",
      " - ETA: 2:55 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 2/11 [====>.........................]                           \n",
      " - ETA: 2:23 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 3/11 [=======>......................]                           \n",
      " - ETA: 1:58 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 4/11 [=========>....................]                           \n",
      " - ETA: 1:33 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 5/11 [============>.................]                           \n",
      " - ETA: 1:14 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 6/11 [===============>..............]                           \n",
      " - ETA: 59s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 \n",
      "                                                                \n",
      " 7/11 [==================>...........]                           \n",
      " - ETA: 46s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      " 8/11 [====================>.........]                           \n",
      " - ETA: 33s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      " 9/11 [=======================>......]                           \n",
      " - ETA: 22s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      "10/11 [==========================>...]                           \n",
      " - ETA: 11s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      "11/11 [==============================]                           \n",
      " - 133s 12s/step - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_36: 0.0000e+00 - val_recall_36: 0.0000e+00\n",
      "\n",
      "Epoch 7/7                                                        \n",
      " 1/11 [=>............................]                           \n",
      " - ETA: 1:48 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 2/11 [====>.........................]                           \n",
      " - ETA: 1:33 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 3/11 [=======>......................]                           \n",
      " - ETA: 1:19 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 4/11 [=========>....................]                           \n",
      " - ETA: 1:05 - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                 \n",
      " 5/11 [============>.................]                           \n",
      " - ETA: 54s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 \n",
      "                                                                \n",
      " 6/11 [===============>..............]                           \n",
      " - ETA: 44s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      " 7/11 [==================>...........]                           \n",
      " - ETA: 35s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      " 8/11 [====================>.........]                           \n",
      " - ETA: 26s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      " 9/11 [=======================>......]                           \n",
      " - ETA: 17s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "                                                                \n",
      "10/11 [==========================>...]                           \n",
      " - ETA: 9s - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 \n",
      "                                                                 \n",
      "11/11 [==============================]                           \n",
      " - 128s 12s/step - loss: 0.3833 - accuracy: 0.9750 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_36: 0.0000e+00 - val_recall_36: 0.0000e+00\n",
      "\n",
      "Best validation acc of epoch: 1.0                                \n",
      "Epoch 1/5                                                        \n",
      " 1/11 [=>............................]                           \n",
      " - ETA: 1:13 - loss: 21.2281 - accuracy: 0.0750 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                \n",
      " 2/11 [====>.........................]                           \n",
      " - ETA: 55s - loss: 10.6141 - accuracy: 0.5375 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00 \n",
      "                                                                 \n",
      " 3/11 [=======>......................]                           \n",
      " - ETA: 48s - loss: 7.0760 - accuracy: 0.6917 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00 \n",
      "                                                                \n",
      " 4/11 [=========>....................]                           \n",
      " - ETA: 42s - loss: 5.3070 - accuracy: 0.7688 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 5/11 [============>.................]                           \n",
      " - ETA: 36s - loss: 4.2456 - accuracy: 0.8150 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 6/11 [===============>..............]                           \n",
      " - ETA: 31s - loss: 3.5380 - accuracy: 0.8458 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 7/11 [==================>...........]                           \n",
      " - ETA: 26s - loss: 3.0326 - accuracy: 0.8679 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 8/11 [====================>.........]                           \n",
      " - ETA: 20s - loss: 2.6535 - accuracy: 0.8844 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 9/11 [=======================>......]                           \n",
      " - ETA: 13s - loss: 2.3587 - accuracy: 0.8972 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      "10/11 [==========================>...]                           \n",
      " - ETA: 6s - loss: 2.1228 - accuracy: 0.9075 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00 \n",
      "                                                                 \n",
      "11/11 [==============================]                           \n",
      " - 85s 8s/step - loss: 1.9298 - accuracy: 0.9159 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00 - val_loss: 2.2723e-07 - val_accuracy: 1.0000 - val_precision_37: 0.0000e+00 - val_recall_37: 0.0000e+00\n",
      "\n",
      "Epoch 2/5                                                        \n",
      " 1/11 [=>............................]                           \n",
      " - ETA: 50s - loss: 8.6991e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 2/11 [====>.........................]                           \n",
      " - ETA: 45s - loss: 8.6991e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 3/11 [=======>......................]                           \n",
      " - ETA: 39s - loss: 8.6991e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 4/11 [=========>....................]                           \n",
      " - ETA: 35s - loss: 8.6991e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 5/11 [============>.................]                           \n",
      " - ETA: 31s - loss: 8.6991e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 6/11 [===============>..............]                           \n",
      " - ETA: 26s - loss: 8.6991e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 7/11 [==================>...........]                           \n",
      " - ETA: 21s - loss: 8.6990e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 8/11 [====================>.........]                           \n",
      " - ETA: 15s - loss: 8.6990e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 9/11 [=======================>......]                           \n",
      " - ETA: 10s - loss: 8.6990e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      "10/11 [==========================>...]                           \n",
      " - ETA: 5s - loss: 8.6990e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00 \n",
      "                                                                 \n",
      "11/11 [==============================]                           \n",
      " - 62s 6s/step - loss: 8.6990e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00 - val_loss: 2.2722e-07 - val_accuracy: 1.0000 - val_precision_37: 0.0000e+00 - val_recall_37: 0.0000e+00\n",
      "\n",
      "Epoch 3/5                                                        \n",
      " 1/11 [=>............................]                           \n",
      " - ETA: 38s - loss: 8.6987e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 2/11 [====>.........................]                           \n",
      " - ETA: 33s - loss: 8.6987e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 3/11 [=======>......................]                           \n",
      " - ETA: 30s - loss: 8.6987e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 4/11 [=========>....................]                           \n",
      " - ETA: 28s - loss: 8.6987e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 5/11 [============>.................]                           \n",
      " - ETA: 24s - loss: 8.6987e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 6/11 [===============>..............]                           \n",
      " - ETA: 20s - loss: 8.6987e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 7/11 [==================>...........]                           \n",
      " - ETA: 16s - loss: 8.6986e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 8/11 [====================>.........]                           \n",
      " - ETA: 12s - loss: 8.6986e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 9/11 [=======================>......]                           \n",
      " - ETA: 8s - loss: 8.6986e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00 \n",
      "                                                                 \n",
      "10/11 [==========================>...]                           \n",
      " - ETA: 4s - loss: 8.6986e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                 \n",
      "11/11 [==============================]                           \n",
      " - 52s 5s/step - loss: 8.6986e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00 - val_loss: 2.2721e-07 - val_accuracy: 1.0000 - val_precision_37: 0.0000e+00 - val_recall_37: 0.0000e+00\n",
      "\n",
      "Epoch 4/5                                                        \n",
      " 1/11 [=>............................]                           \n",
      " - ETA: 40s - loss: 8.6984e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 2/11 [====>.........................]                           \n",
      " - ETA: 36s - loss: 8.6984e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                \n",
      " 3/11 [=======>......................]                           \n",
      " - ETA: 33s - loss: 8.6983e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 4/11 [=========>....................]                           \n",
      " - ETA: 31s - loss: 8.6983e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 5/11 [============>.................]                           \n",
      " - ETA: 26s - loss: 8.6983e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 6/11 [===============>..............]                           \n",
      " - ETA: 22s - loss: 8.6983e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 7/11 [==================>...........]                           \n",
      " - ETA: 18s - loss: 8.6983e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 8/11 [====================>.........]                           \n",
      " - ETA: 13s - loss: 8.6983e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 9/11 [=======================>......]                           \n",
      " - ETA: 9s - loss: 8.6982e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00 \n",
      "                                                                 \n",
      "10/11 [==========================>...]                           \n",
      " - ETA: 4s - loss: 8.6982e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                 \n",
      "11/11 [==============================]                           \n",
      " - 55s 5s/step - loss: 8.6982e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00 - val_loss: 2.2720e-07 - val_accuracy: 1.0000 - val_precision_37: 0.0000e+00 - val_recall_37: 0.0000e+00\n",
      "\n",
      "Epoch 5/5                                                        \n",
      " 1/11 [=>............................]                           \n",
      " - ETA: 37s - loss: 8.6980e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 2/11 [====>.........................]                           \n",
      " - ETA: 33s - loss: 8.6980e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 3/11 [=======>......................]                           \n",
      " - ETA: 31s - loss: 8.6980e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 4/11 [=========>....................]                           \n",
      " - ETA: 29s - loss: 8.6979e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 5/11 [============>.................]                           \n",
      " - ETA: 25s - loss: 8.6979e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 6/11 [===============>..............]                           \n",
      " - ETA: 22s - loss: 8.6979e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 7/11 [==================>...........]                           \n",
      " - ETA: 18s - loss: 8.6979e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 8/11 [====================>.........]                           \n",
      " - ETA: 14s - loss: 8.6979e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                \n",
      " 9/11 [=======================>......]                           \n",
      " - ETA: 9s - loss: 8.6979e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00 \n",
      "                                                                 \n",
      "10/11 [==========================>...]                           \n",
      " - ETA: 4s - loss: 8.6978e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00\n",
      "                                                                 \n",
      "11/11 [==============================]                           \n",
      " - 59s 5s/step - loss: 8.6978e-11 - accuracy: 1.0000 - precision_37: 0.0000e+00 - recall_37: 0.0000e+00 - val_loss: 2.2719e-07 - val_accuracy: 1.0000 - val_precision_37: 0.0000e+00 - val_recall_37: 0.0000e+00\n",
      "\n",
      "Best validation acc of epoch: 0.9999997727724406                 \n",
      "Epoch 1/7                                                        \n",
      " 1/47 [..............................]                           \n",
      " - ETA: 1:21 - loss: 6.2854 - accuracy: 0.5000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      " 2/47 [>.............................]                           \n",
      " - ETA: 53s - loss: 3.1427 - accuracy: 0.7500 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00 \n",
      "                                                                \n",
      " 3/47 [>.............................]                           \n",
      " - ETA: 43s - loss: 2.0951 - accuracy: 0.8333 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 4/47 [=>............................]                           \n",
      " - ETA: 37s - loss: 1.5713 - accuracy: 0.8750 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 5/47 [==>...........................]                           \n",
      " - ETA: 34s - loss: 1.2571 - accuracy: 0.9000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 6/47 [==>...........................]                           \n",
      " - ETA: 31s - loss: 1.0476 - accuracy: 0.9167 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 7/47 [===>..........................]                           \n",
      " - ETA: 29s - loss: 0.8979 - accuracy: 0.9286 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 8/47 [====>.........................]                           \n",
      " - ETA: 28s - loss: 0.7857 - accuracy: 0.9375 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 9/47 [====>.........................]                           \n",
      " - ETA: 27s - loss: 0.6984 - accuracy: 0.9444 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "10/47 [=====>........................]                           \n",
      " - ETA: 25s - loss: 0.6285 - accuracy: 0.9500 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "11/47 [======>.......................]                           \n",
      " - ETA: 24s - loss: 0.5714 - accuracy: 0.9545 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "12/47 [======>.......................]                           \n",
      " - ETA: 24s - loss: 0.5238 - accuracy: 0.9583 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "13/47 [=======>......................]                           \n",
      " - ETA: 25s - loss: 0.4835 - accuracy: 0.9615 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "14/47 [=======>......................]                           \n",
      " - ETA: 26s - loss: 0.4490 - accuracy: 0.9643 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/47 [========>.....................]                           \n",
      " - ETA: 26s - loss: 0.4190 - accuracy: 0.9667 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "16/47 [=========>....................]                           \n",
      " - ETA: 26s - loss: 0.3928 - accuracy: 0.9688 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "17/47 [=========>....................]                           \n",
      " - ETA: 25s - loss: 0.3697 - accuracy: 0.9706 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "18/47 [==========>...................]                           \n",
      " - ETA: 25s - loss: 0.3492 - accuracy: 0.9722 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "19/47 [===========>..................]                           \n",
      " - ETA: 25s - loss: 0.3308 - accuracy: 0.9737 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "20/47 [===========>..................]                           \n",
      " - ETA: 24s - loss: 0.3143 - accuracy: 0.9750 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "21/47 [============>.................]                           \n",
      " - ETA: 24s - loss: 0.2993 - accuracy: 0.9762 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "22/47 [=============>................]                           \n",
      " - ETA: 23s - loss: 0.2857 - accuracy: 0.9773 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "23/47 [=============>................]                           \n",
      " - ETA: 22s - loss: 0.2733 - accuracy: 0.9783 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "24/47 [==============>...............]                           \n",
      " - ETA: 21s - loss: 0.2619 - accuracy: 0.9792 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "25/47 [==============>...............]                           \n",
      " - ETA: 21s - loss: 0.2514 - accuracy: 0.9800 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "26/47 [===============>..............]                           \n",
      " - ETA: 20s - loss: 0.2417 - accuracy: 0.9808 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "27/47 [================>.............]                           \n",
      " - ETA: 19s - loss: 0.2328 - accuracy: 0.9815 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "28/47 [================>.............]                           \n",
      " - ETA: 18s - loss: 0.2245 - accuracy: 0.9821 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "29/47 [=================>............]                           \n",
      " - ETA: 17s - loss: 0.2167 - accuracy: 0.9828 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "30/47 [==================>...........]                           \n",
      " - ETA: 16s - loss: 0.2095 - accuracy: 0.9833 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "31/47 [==================>...........]                           \n",
      " - ETA: 15s - loss: 0.2028 - accuracy: 0.9839 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "32/47 [===================>..........]                           \n",
      " - ETA: 15s - loss: 0.1964 - accuracy: 0.9844 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "33/47 [====================>.........]                           \n",
      " - ETA: 14s - loss: 0.1905 - accuracy: 0.9848 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "34/47 [====================>.........]                           \n",
      " - ETA: 13s - loss: 0.1849 - accuracy: 0.9853 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "35/47 [=====================>........]                           \n",
      " - ETA: 12s - loss: 0.1796 - accuracy: 0.9857 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "36/47 [=====================>........]                           \n",
      " - ETA: 11s - loss: 0.1746 - accuracy: 0.9861 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "37/47 [======================>.......]                           \n",
      " - ETA: 10s - loss: 0.1699 - accuracy: 0.9865 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "38/47 [=======================>......]                           \n",
      " - ETA: 9s - loss: 0.1654 - accuracy: 0.9868 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00 \n",
      "                                                                 \n",
      "39/47 [=======================>......]                           \n",
      " - ETA: 8s - loss: 0.1612 - accuracy: 0.9872 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "40/47 [========================>.....]                           \n",
      " - ETA: 7s - loss: 0.1571 - accuracy: 0.9875 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "41/47 [=========================>....]                           \n",
      " - ETA: 6s - loss: 0.1533 - accuracy: 0.9878 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "42/47 [=========================>....]                           \n",
      " - ETA: 5s - loss: 0.1497 - accuracy: 0.9881 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "43/47 [==========================>...]                           \n",
      " - ETA: 4s - loss: 0.1462 - accuracy: 0.9884 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "44/47 [===========================>..]                           \n",
      " - ETA: 3s - loss: 0.1428 - accuracy: 0.9886 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "45/47 [===========================>..]                           \n",
      " - ETA: 2s - loss: 0.1397 - accuracy: 0.9889 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "46/47 [============================>.]                           \n",
      " - ETA: 1s - loss: 0.1366 - accuracy: 0.9891 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "47/47 [==============================]                           \n",
      " - 59s 1s/step - loss: 0.1337 - accuracy: 0.9894 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_38: 0.0000e+00 - val_recall_38: 0.0000e+00\n",
      "\n",
      "Epoch 2/7                                                        \n",
      " 1/47 [..............................]                           \n",
      " - ETA: 35s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 2/47 [>.............................]                           \n",
      " - ETA: 36s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 3/47 [>.............................]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - ETA: 35s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 4/47 [=>............................]                           \n",
      " - ETA: 33s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 5/47 [==>...........................]                           \n",
      " - ETA: 33s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 6/47 [==>...........................]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 7/47 [===>..........................]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 8/47 [====>.........................]                           \n",
      " - ETA: 35s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 9/47 [====>.........................]                           \n",
      " - ETA: 38s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "10/47 [=====>........................]                           \n",
      " - ETA: 40s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "11/47 [======>.......................]                           \n",
      " - ETA: 42s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "12/47 [======>.......................]                           \n",
      " - ETA: 43s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "13/47 [=======>......................]                           \n",
      " - ETA: 44s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "14/47 [=======>......................]                           \n",
      " - ETA: 44s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "15/47 [========>.....................]                           \n",
      " - ETA: 44s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "16/47 [=========>....................]                           \n",
      " - ETA: 44s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "17/47 [=========>....................]                           \n",
      " - ETA: 44s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "18/47 [==========>...................]                           \n",
      " - ETA: 43s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "19/47 [===========>..................]                           \n",
      " - ETA: 42s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "20/47 [===========>..................]                           \n",
      " - ETA: 41s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "21/47 [============>.................]                           \n",
      " - ETA: 39s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "22/47 [=============>................]                           \n",
      " - ETA: 38s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "23/47 [=============>................]                           \n",
      " - ETA: 37s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "24/47 [==============>...............]                           \n",
      " - ETA: 35s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "25/47 [==============>...............]                           \n",
      " - ETA: 34s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "26/47 [===============>..............]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "27/47 [================>.............]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "28/47 [================>.............]                           \n",
      " - ETA: 29s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "29/47 [=================>............]                           \n",
      " - ETA: 28s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "30/47 [==================>...........]                           \n",
      " - ETA: 26s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "31/47 [==================>...........]                           \n",
      " - ETA: 24s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "32/47 [===================>..........]                           \n",
      " - ETA: 23s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "33/47 [====================>.........]                           \n",
      " - ETA: 21s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "34/47 [====================>.........]                           \n",
      " - ETA: 20s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "35/47 [=====================>........]                           \n",
      " - ETA: 18s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "36/47 [=====================>........]                           \n",
      " - ETA: 17s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "37/47 [======================>.......]                           \n",
      " - ETA: 15s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "38/47 [=======================>......]                           \n",
      " - ETA: 13s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                \n",
      "39/47 [=======================>......]                           \n",
      " - ETA: 12s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "40/47 [========================>.....]                           \n",
      " - ETA: 10s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "41/47 [=========================>....]                           \n",
      " - ETA: 9s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00 \n",
      "                                                                 \n",
      "42/47 [=========================>....]                           \n",
      " - ETA: 7s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "43/47 [==========================>...]                           \n",
      " - ETA: 6s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "44/47 [===========================>..]                           \n",
      " - ETA: 4s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "45/47 [===========================>..]                           \n",
      " - ETA: 3s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "46/47 [============================>.]                           \n",
      " - ETA: 1s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "47/47 [==============================]                           \n",
      " - 79s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_38: 0.0000e+00 - val_recall_38: 0.0000e+00\n",
      "\n",
      "Epoch 3/7                                                        \n",
      " 1/47 [..............................]                           \n",
      " - ETA: 36s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 2/47 [>.............................]                           \n",
      " - ETA: 34s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 3/47 [>.............................]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 4/47 [=>............................]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 5/47 [==>...........................]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 6/47 [==>...........................]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 7/47 [===>..........................]                           \n",
      " - ETA: 36s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 8/47 [====>.........................]                           \n",
      " - ETA: 38s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 9/47 [====>.........................]                           \n",
      " - ETA: 40s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "10/47 [=====>........................]                           \n",
      " - ETA: 41s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "11/47 [======>.......................]                           \n",
      " - ETA: 41s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "12/47 [======>.......................]                           \n",
      " - ETA: 41s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "13/47 [=======>......................]                           \n",
      " - ETA: 41s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "14/47 [=======>......................]                           \n",
      " - ETA: 40s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "15/47 [========>.....................]                           \n",
      " - ETA: 39s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "16/47 [=========>....................]                           \n",
      " - ETA: 39s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "17/47 [=========>....................]                           \n",
      " - ETA: 38s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "18/47 [==========>...................]                           \n",
      " - ETA: 37s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "19/47 [===========>..................]                           \n",
      " - ETA: 36s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "20/47 [===========>..................]                           \n",
      " - ETA: 35s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "21/47 [============>.................]                           \n",
      " - ETA: 33s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "22/47 [=============>................]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "23/47 [=============>................]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "24/47 [==============>...............]                           \n",
      " - ETA: 30s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "25/47 [==============>...............]                           \n",
      " - ETA: 28s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "26/47 [===============>..............]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - ETA: 27s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "27/47 [================>.............]                           \n",
      " - ETA: 26s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "28/47 [================>.............]                           \n",
      " - ETA: 25s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "29/47 [=================>............]                           \n",
      " - ETA: 23s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "30/47 [==================>...........]                           \n",
      " - ETA: 22s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "31/47 [==================>...........]                           \n",
      " - ETA: 21s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "32/47 [===================>..........]                           \n",
      " - ETA: 20s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "33/47 [====================>.........]                           \n",
      " - ETA: 18s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "34/47 [====================>.........]                           \n",
      " - ETA: 17s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "35/47 [=====================>........]                           \n",
      " - ETA: 16s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "36/47 [=====================>........]                           \n",
      " - ETA: 14s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "37/47 [======================>.......]                           \n",
      " - ETA: 13s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "38/47 [=======================>......]                           \n",
      " - ETA: 12s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "39/47 [=======================>......]                           \n",
      " - ETA: 10s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "40/47 [========================>.....]                           \n",
      " - ETA: 9s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00 \n",
      "                                                                 \n",
      "41/47 [=========================>....]                           \n",
      " - ETA: 8s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "42/47 [=========================>....]                           \n",
      " - ETA: 6s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "43/47 [==========================>...]                           \n",
      " - ETA: 5s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "44/47 [===========================>..]                           \n",
      " - ETA: 4s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "45/47 [===========================>..]                           \n",
      " - ETA: 2s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "46/47 [============================>.]                           \n",
      " - ETA: 1s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "47/47 [==============================]                           \n",
      " - 72s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_38: 0.0000e+00 - val_recall_38: 0.0000e+00\n",
      "\n",
      "Epoch 4/7                                                        \n",
      " 1/47 [..............................]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 2/47 [>.............................]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 3/47 [>.............................]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 4/47 [=>............................]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 5/47 [==>...........................]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 6/47 [==>...........................]                           \n",
      " - ETA: 30s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 7/47 [===>..........................]                           \n",
      " - ETA: 33s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 8/47 [====>.........................]                           \n",
      " - ETA: 36s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 9/47 [====>.........................]                           \n",
      " - ETA: 38s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "10/47 [=====>........................]                           \n",
      " - ETA: 40s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "11/47 [======>.......................]                           \n",
      " - ETA: 40s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "12/47 [======>.......................]                           \n",
      " - ETA: 40s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "13/47 [=======>......................]                           \n",
      " - ETA: 40s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/47 [=======>......................]                           \n",
      " - ETA: 39s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "15/47 [========>.....................]                           \n",
      " - ETA: 39s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "16/47 [=========>....................]                           \n",
      " - ETA: 38s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "17/47 [=========>....................]                           \n",
      " - ETA: 37s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "18/47 [==========>...................]                           \n",
      " - ETA: 36s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "19/47 [===========>..................]                           \n",
      " - ETA: 35s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "20/47 [===========>..................]                           \n",
      " - ETA: 34s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "21/47 [============>.................]                           \n",
      " - ETA: 33s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "22/47 [=============>................]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "23/47 [=============>................]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "24/47 [==============>...............]                           \n",
      " - ETA: 30s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "25/47 [==============>...............]                           \n",
      " - ETA: 29s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "26/47 [===============>..............]                           \n",
      " - ETA: 28s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "27/47 [================>.............]                           \n",
      " - ETA: 26s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "28/47 [================>.............]                           \n",
      " - ETA: 25s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "29/47 [=================>............]                           \n",
      " - ETA: 24s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "30/47 [==================>...........]                           \n",
      " - ETA: 23s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "31/47 [==================>...........]                           \n",
      " - ETA: 21s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "32/47 [===================>..........]                           \n",
      " - ETA: 20s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "33/47 [====================>.........]                           \n",
      " - ETA: 19s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "34/47 [====================>.........]                           \n",
      " - ETA: 17s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "35/47 [=====================>........]                           \n",
      " - ETA: 16s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "36/47 [=====================>........]                           \n",
      " - ETA: 15s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "37/47 [======================>.......]                           \n",
      " - ETA: 13s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "38/47 [=======================>......]                           \n",
      " - ETA: 12s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "39/47 [=======================>......]                           \n",
      " - ETA: 10s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "40/47 [========================>.....]                           \n",
      " - ETA: 9s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00 \n",
      "                                                                 \n",
      "41/47 [=========================>....]                           \n",
      " - ETA: 8s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "42/47 [=========================>....]                           \n",
      " - ETA: 6s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "43/47 [==========================>...]                           \n",
      " - ETA: 5s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "44/47 [===========================>..]                           \n",
      " - ETA: 4s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "45/47 [===========================>..]                           \n",
      " - ETA: 2s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "46/47 [============================>.]                           \n",
      " - ETA: 1s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "47/47 [==============================]                           \n",
      " - 72s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_38: 0.0000e+00 - val_recall_38: 0.0000e+00\n",
      "\n",
      "Epoch 5/7                                                        \n",
      " 1/47 [..............................]                           \n",
      " - ETA: 33s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                \n",
      " 2/47 [>.............................]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 3/47 [>.............................]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 4/47 [=>............................]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 5/47 [==>...........................]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 6/47 [==>...........................]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 7/47 [===>..........................]                           \n",
      " - ETA: 35s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 8/47 [====>.........................]                           \n",
      " - ETA: 37s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 9/47 [====>.........................]                           \n",
      " - ETA: 39s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "10/47 [=====>........................]                           \n",
      " - ETA: 40s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "11/47 [======>.......................]                           \n",
      " - ETA: 41s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "12/47 [======>.......................]                           \n",
      " - ETA: 41s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "13/47 [=======>......................]                           \n",
      " - ETA: 40s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "14/47 [=======>......................]                           \n",
      " - ETA: 40s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "15/47 [========>.....................]                           \n",
      " - ETA: 39s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "16/47 [=========>....................]                           \n",
      " - ETA: 38s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "17/47 [=========>....................]                           \n",
      " - ETA: 37s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "18/47 [==========>...................]                           \n",
      " - ETA: 36s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "19/47 [===========>..................]                           \n",
      " - ETA: 35s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "20/47 [===========>..................]                           \n",
      " - ETA: 34s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "21/47 [============>.................]                           \n",
      " - ETA: 33s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "22/47 [=============>................]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "23/47 [=============>................]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "24/47 [==============>...............]                           \n",
      " - ETA: 30s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "25/47 [==============>...............]                           \n",
      " - ETA: 29s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "26/47 [===============>..............]                           \n",
      " - ETA: 27s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "27/47 [================>.............]                           \n",
      " - ETA: 26s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "28/47 [================>.............]                           \n",
      " - ETA: 25s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "29/47 [=================>............]                           \n",
      " - ETA: 24s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "30/47 [==================>...........]                           \n",
      " - ETA: 22s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "31/47 [==================>...........]                           \n",
      " - ETA: 21s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "32/47 [===================>..........]                           \n",
      " - ETA: 20s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "33/47 [====================>.........]                           \n",
      " - ETA: 18s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "34/47 [====================>.........]                           \n",
      " - ETA: 17s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "35/47 [=====================>........]                           \n",
      " - ETA: 16s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "36/47 [=====================>........]                           \n",
      " - ETA: 14s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/47 [======================>.......]                           \n",
      " - ETA: 13s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "38/47 [=======================>......]                           \n",
      " - ETA: 12s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "39/47 [=======================>......]                           \n",
      " - ETA: 10s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "40/47 [========================>.....]                           \n",
      " - ETA: 9s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00 \n",
      "                                                                 \n",
      "41/47 [=========================>....]                           \n",
      " - ETA: 8s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "42/47 [=========================>....]                           \n",
      " - ETA: 6s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "43/47 [==========================>...]                           \n",
      " - ETA: 5s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "44/47 [===========================>..]                           \n",
      " - ETA: 4s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "45/47 [===========================>..]                           \n",
      " - ETA: 2s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "46/47 [============================>.]                           \n",
      " - ETA: 1s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "47/47 [==============================]                           \n",
      " - 72s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_38: 0.0000e+00 - val_recall_38: 0.0000e+00\n",
      "\n",
      "Epoch 6/7                                                        \n",
      " 1/47 [..............................]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 2/47 [>.............................]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 3/47 [>.............................]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 4/47 [=>............................]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 5/47 [==>...........................]                           \n",
      " - ETA: 30s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 6/47 [==>...........................]                           \n",
      " - ETA: 30s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 7/47 [===>..........................]                           \n",
      " - ETA: 34s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 8/47 [====>.........................]                           \n",
      " - ETA: 36s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 9/47 [====>.........................]                           \n",
      " - ETA: 38s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "10/47 [=====>........................]                           \n",
      " - ETA: 40s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "11/47 [======>.......................]                           \n",
      " - ETA: 41s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "12/47 [======>.......................]                           \n",
      " - ETA: 41s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "13/47 [=======>......................]                           \n",
      " - ETA: 42s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "14/47 [=======>......................]                           \n",
      " - ETA: 42s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "15/47 [========>.....................]                           \n",
      " - ETA: 42s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "16/47 [=========>....................]                           \n",
      " - ETA: 42s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "17/47 [=========>....................]                           \n",
      " - ETA: 41s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "18/47 [==========>...................]                           \n",
      " - ETA: 41s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "19/47 [===========>..................]                           \n",
      " - ETA: 40s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "20/47 [===========>..................]                           \n",
      " - ETA: 39s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "21/47 [============>.................]                           \n",
      " - ETA: 38s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "22/47 [=============>................]                           \n",
      " - ETA: 37s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "23/47 [=============>................]                           \n",
      " - ETA: 35s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "24/47 [==============>...............]                           \n",
      " - ETA: 34s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                \n",
      "25/47 [==============>...............]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "26/47 [===============>..............]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "27/47 [================>.............]                           \n",
      " - ETA: 29s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "28/47 [================>.............]                           \n",
      " - ETA: 28s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "29/47 [=================>............]                           \n",
      " - ETA: 26s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "30/47 [==================>...........]                           \n",
      " - ETA: 24s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "31/47 [==================>...........]                           \n",
      " - ETA: 23s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "32/47 [===================>..........]                           \n",
      " - ETA: 21s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "33/47 [====================>.........]                           \n",
      " - ETA: 20s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "34/47 [====================>.........]                           \n",
      " - ETA: 18s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "35/47 [=====================>........]                           \n",
      " - ETA: 17s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "36/47 [=====================>........]                           \n",
      " - ETA: 15s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "37/47 [======================>.......]                           \n",
      " - ETA: 14s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "38/47 [=======================>......]                           \n",
      " - ETA: 12s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "39/47 [=======================>......]                           \n",
      " - ETA: 11s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "40/47 [========================>.....]                           \n",
      " - ETA: 10s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "41/47 [=========================>....]                           \n",
      " - ETA: 8s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00 \n",
      "                                                                 \n",
      "42/47 [=========================>....]                           \n",
      " - ETA: 7s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "43/47 [==========================>...]                           \n",
      " - ETA: 5s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "44/47 [===========================>..]                           \n",
      " - ETA: 4s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "45/47 [===========================>..]                           \n",
      " - ETA: 2s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "46/47 [============================>.]                           \n",
      " - ETA: 1s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "47/47 [==============================]                           \n",
      " - 75s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_38: 0.0000e+00 - val_recall_38: 0.0000e+00\n",
      "\n",
      "Epoch 7/7                                                        \n",
      " 1/47 [..............................]                           \n",
      " - ETA: 36s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 2/47 [>.............................]                           \n",
      " - ETA: 34s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 3/47 [>.............................]                           \n",
      " - ETA: 34s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 4/47 [=>............................]                           \n",
      " - ETA: 33s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 5/47 [==>...........................]                           \n",
      " - ETA: 33s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 6/47 [==>...........................]                           \n",
      " - ETA: 34s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 7/47 [===>..........................]                           \n",
      " - ETA: 41s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 8/47 [====>.........................]                           \n",
      " - ETA: 44s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      " 9/47 [====>.........................]                           \n",
      " - ETA: 46s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "10/47 [=====>........................]                           \n",
      " - ETA: 47s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "11/47 [======>.......................]                           \n",
      " - ETA: 48s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "12/47 [======>.......................]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - ETA: 48s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "13/47 [=======>......................]                           \n",
      " - ETA: 48s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "14/47 [=======>......................]                           \n",
      " - ETA: 47s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "15/47 [========>.....................]                           \n",
      " - ETA: 47s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "16/47 [=========>....................]                           \n",
      " - ETA: 45s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "17/47 [=========>....................]                           \n",
      " - ETA: 44s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "18/47 [==========>...................]                           \n",
      " - ETA: 43s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "19/47 [===========>..................]                           \n",
      " - ETA: 41s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "20/47 [===========>..................]                           \n",
      " - ETA: 40s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "21/47 [============>.................]                           \n",
      " - ETA: 38s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "22/47 [=============>................]                           \n",
      " - ETA: 37s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "23/47 [=============>................]                           \n",
      " - ETA: 35s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "24/47 [==============>...............]                           \n",
      " - ETA: 33s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "25/47 [==============>...............]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "26/47 [===============>..............]                           \n",
      " - ETA: 30s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "27/47 [================>.............]                           \n",
      " - ETA: 29s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "28/47 [================>.............]                           \n",
      " - ETA: 27s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "29/47 [=================>............]                           \n",
      " - ETA: 26s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "30/47 [==================>...........]                           \n",
      " - ETA: 24s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "31/47 [==================>...........]                           \n",
      " - ETA: 23s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "32/47 [===================>..........]                           \n",
      " - ETA: 21s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "33/47 [====================>.........]                           \n",
      " - ETA: 20s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "34/47 [====================>.........]                           \n",
      " - ETA: 18s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "35/47 [=====================>........]                           \n",
      " - ETA: 17s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "36/47 [=====================>........]                           \n",
      " - ETA: 15s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "37/47 [======================>.......]                           \n",
      " - ETA: 14s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "38/47 [=======================>......]                           \n",
      " - ETA: 12s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "39/47 [=======================>......]                           \n",
      " - ETA: 11s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                \n",
      "40/47 [========================>.....]                           \n",
      " - ETA: 9s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00 \n",
      "                                                                 \n",
      "41/47 [=========================>....]                           \n",
      " - ETA: 8s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "42/47 [=========================>....]                           \n",
      " - ETA: 7s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "43/47 [==========================>...]                           \n",
      " - ETA: 5s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "44/47 [===========================>..]                           \n",
      " - ETA: 4s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "45/47 [===========================>..]                           \n",
      " - ETA: 2s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "46/47 [============================>.]                           \n",
      " - ETA: 1s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00\n",
      "                                                                 \n",
      "47/47 [==============================]                           \n",
      " - 72s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_38: 0.0000e+00 - recall_38: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - val_precision_38: 0.0000e+00 - val_recall_38: 0.0000e+00\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation acc of epoch: 1.0                                \n",
      "Epoch 1/3                                                        \n",
      " 1/23 [>.............................]                           \n",
      " - ETA: 1:29 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 2/23 [=>............................]                           \n",
      " - ETA: 1:12 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 3/23 [==>...........................]                           \n",
      " - ETA: 1:05 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 4/23 [====>.........................]                           \n",
      " - ETA: 1:00 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 5/23 [=====>........................]                           \n",
      " - ETA: 55s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00 \n",
      "                                                                \n",
      " 6/23 [======>.......................]                           \n",
      " - ETA: 52s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      " 7/23 [========>.....................]                           \n",
      " - ETA: 49s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      " 8/23 [=========>....................]                           \n",
      " - ETA: 46s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      " 9/23 [==========>...................]                           \n",
      " - ETA: 42s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "10/23 [============>.................]                           \n",
      " - ETA: 39s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "11/23 [=============>................]                           \n",
      " - ETA: 36s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "12/23 [==============>...............]                           \n",
      " - ETA: 33s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "13/23 [===============>..............]                           \n",
      " - ETA: 30s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "14/23 [=================>............]                           \n",
      " - ETA: 27s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "15/23 [==================>...........]                           \n",
      " - ETA: 24s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "16/23 [===================>..........]                           \n",
      " - ETA: 21s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "17/23 [=====================>........]                           \n",
      " - ETA: 18s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "18/23 [======================>.......]                           \n",
      " - ETA: 15s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "19/23 [=======================>......]                           \n",
      " - ETA: 12s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "20/23 [=========================>....]                           \n",
      " - ETA: 9s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00 \n",
      "                                                                 \n",
      "21/23 [==========================>...]                           \n",
      " - ETA: 6s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      "22/23 [===========================>..]                           \n",
      " - ETA: 3s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      "23/23 [==============================]                           \n",
      " - 81s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00 - val_loss: 2.2874 - val_accuracy: 0.8500 - val_precision_39: 0.0000e+00 - val_recall_39: 0.0000e+00\n",
      "\n",
      "Epoch 2/3                                                        \n",
      " 1/23 [>.............................]                           \n",
      " - ETA: 1:13 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 2/23 [=>............................]                           \n",
      " - ETA: 1:10 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 3/23 [==>...........................]                           \n",
      " - ETA: 1:07 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 4/23 [====>.........................]                           \n",
      " - ETA: 1:03 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 5/23 [=====>........................]                           \n",
      " - ETA: 59s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00 \n",
      "                                                                \n",
      " 6/23 [======>.......................]                           \n",
      " - ETA: 55s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      " 7/23 [========>.....................]                           \n",
      " - ETA: 52s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      " 8/23 [=========>....................]                           \n",
      " - ETA: 49s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      " 9/23 [==========>...................]                           \n",
      " - ETA: 47s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "10/23 [============>.................]                           \n",
      " - ETA: 45s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "11/23 [=============>................]                           \n",
      " - ETA: 43s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/23 [==============>...............]                           \n",
      " - ETA: 40s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "13/23 [===============>..............]                           \n",
      " - ETA: 38s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "14/23 [=================>............]                           \n",
      " - ETA: 35s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "15/23 [==================>...........]                           \n",
      " - ETA: 32s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "16/23 [===================>..........]                           \n",
      " - ETA: 28s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "17/23 [=====================>........]                           \n",
      " - ETA: 24s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "18/23 [======================>.......]                           \n",
      " - ETA: 20s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "19/23 [=======================>......]                           \n",
      " - ETA: 16s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "20/23 [=========================>....]                           \n",
      " - ETA: 12s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "21/23 [==========================>...]                           \n",
      " - ETA: 8s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00 \n",
      "                                                                 \n",
      "22/23 [===========================>..]                           \n",
      " - ETA: 4s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      "23/23 [==============================]                           \n",
      " - 101s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00 - val_loss: 2.2874 - val_accuracy: 0.8500 - val_precision_39: 0.0000e+00 - val_recall_39: 0.0000e+00\n",
      "\n",
      "Epoch 3/3                                                        \n",
      " 1/23 [>.............................]                           \n",
      " - ETA: 1:31 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 2/23 [=>............................]                           \n",
      " - ETA: 1:28 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 3/23 [==>...........................]                           \n",
      " - ETA: 1:23 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 4/23 [====>.........................]                           \n",
      " - ETA: 1:19 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 5/23 [=====>........................]                           \n",
      " - ETA: 1:14 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 6/23 [======>.......................]                           \n",
      " - ETA: 1:10 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 7/23 [========>.....................]                           \n",
      " - ETA: 1:06 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 8/23 [=========>....................]                           \n",
      " - ETA: 1:01 - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      " 9/23 [==========>...................]                           \n",
      " - ETA: 57s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00 \n",
      "                                                                \n",
      "10/23 [============>.................]                           \n",
      " - ETA: 53s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "11/23 [=============>................]                           \n",
      " - ETA: 48s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "12/23 [==============>...............]                           \n",
      " - ETA: 44s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "13/23 [===============>..............]                           \n",
      " - ETA: 39s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "14/23 [=================>............]                           \n",
      " - ETA: 35s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "15/23 [==================>...........]                           \n",
      " - ETA: 31s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "16/23 [===================>..........]                           \n",
      " - ETA: 27s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "17/23 [=====================>........]                           \n",
      " - ETA: 23s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "18/23 [======================>.......]                           \n",
      " - ETA: 19s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "19/23 [=======================>......]                           \n",
      " - ETA: 16s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "20/23 [=========================>....]                           \n",
      " - ETA: 12s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                \n",
      "21/23 [==========================>...]                           \n",
      " - ETA: 8s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00 \n",
      "                                                                 \n",
      "22/23 [===========================>..]                           \n",
      " - ETA: 4s - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00\n",
      "                                                                 \n",
      "23/23 [==============================]                           \n",
      " - 120s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision_39: 0.0000e+00 - recall_39: 0.0000e+00 - val_loss: 2.2874 - val_accuracy: 0.8500 - val_precision_39: 0.0000e+00 - val_recall_39: 0.0000e+00\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation acc of epoch: -1.2873857021331787                \n",
      "100%|| 5/5 [44:44<00:00, 536.91s/trial, best loss: 0.0]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'activation': 0, 'batch_size': 2, 'epochs': 2, 'kernel_size': 1, 'kernel_size_1': 1, 'kernel_size_2': 1, 'kernel_size_3': 2, 'kernel_size_4': 0, 'kernel_size_5': 1, 'optimizer': 2}\n"
     ]
    }
   ],
   "source": [
    "def optimize_model():\n",
    "    \"\"\"Returns a dictionary with the results of the best model.\"\"\"\n",
    "    # define known parameters\n",
    "    layer_size = 4\n",
    "    # Instaniate model\n",
    "    model = Sequential()\n",
    "    # Instantiate TensorBoard to visualize model performance\n",
    "    tensorboard = TensorBoard(log_dir='./Graph')\n",
    "    # Add 3 CNN layers\n",
    "    model.add(Conv2D(layer_size, kernel_size={{choice([(1, 1),(2, 2),(3, 3)])}},\n",
    "                     activation='relu',\n",
    "                     input_shape=(1024, 1024, 3)))\n",
    "    model.add(MaxPooling2D(pool_size={{choice([(1, 1),(2, 2),(3, 3)])}}))\n",
    "    model.add(Conv2D(layer_size,\n",
    "                     kernel_size={{choice([(1, 1),(2, 2),(3, 3)])}},\n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size={{choice([(1, 1),(2, 2),(3, 3)])}}))\n",
    "    model.add(Conv2D(layer_size,\n",
    "                     kernel_size={{choice([(1, 1),(2, 2),(3, 3)])}},\n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size={{choice([(1, 1),(2, 2),(3, 3)])}}))\n",
    "    # Flatten the data\n",
    "    model.add(Flatten())\n",
    "    # Add 1 MLP Layer\n",
    "    model.add(Dense(1, activation={{choice(['sigmoid', 'relu'])}}))\n",
    "    # Compile Model\n",
    "    model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                  optimizer=\n",
    "                      {{choice(\n",
    "                          [keras.optimizers.Adadelta(),\n",
    "                          'sgd', 'adam', 'rmsprop']   \n",
    "                           )}},\n",
    "                  metrics=['accuracy',\n",
    "                           tf.keras.metrics.Precision(),\n",
    "                           tf.keras.metrics.Recall()])\n",
    "    # Train Model   \n",
    "    batch_size={{choice([10, 20, 40])}}\n",
    "    history = model.fit_generator(generator=util.data_gen(df_train, batch_size=batch_size),\n",
    "                                steps_per_epoch=len(df_train['label']) // batch_size,\n",
    "                                epochs={{choice([3, 5, 7])}},\n",
    "                                validation_data=util.data_gen(df_test, batch_size=batch_size),\n",
    "                                validation_steps=len(df_test['label']) // batch_size, \n",
    "                                callbacks=[tensorboard])\n",
    "    \n",
    "    # Get Optimized results\n",
    "    # get the highest validation metrics of the training epochs\n",
    "    val_loss = np.amax(history.history['val_loss'])\n",
    "    print(f'Best validation acc of epoch: {(1-val_loss)}')\n",
    "    return {\n",
    "        'loss': val_loss,\n",
    "        'accuracy': 1-val_loss,\n",
    "        'status': STATUS_OK,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "# find the best model!\n",
    "best_run, best_model = optim.minimize(model=optimize_model,\n",
    "                                    data=data,\n",
    "                                    algo=tpe.suggest,\n",
    "                                    max_evals=5,\n",
    "                                    trials=Trials(),\n",
    "                                    notebook_name='classifications')\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Conclusion: What are the Optimal Hyperparameters?**\n",
    "\n",
    "After using Hyperas, the best hyperparameters appear to be the following (in order to balance model performance with overfitting and efficiency):\n",
    "\n",
    "- Activation Function (for the output layer): Sigmoid\n",
    "- Batch Size: 40\n",
    "- Epochs: 7\n",
    "- Kernel Sizes:\n",
    "    - 1st: 2x2\n",
    "    - 2nd: 2x2\n",
    "    - 3rd: 1x1\n",
    "- Pooling Sizes:\n",
    "    - 1st: 2x2\n",
    "    - 2nd: 3x3\n",
    "    - 3rd: 2x2\n",
    "- Optimizer: RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Summarize, and Save the Model\n",
    "\n",
    "This will help us for future reference, so when we want to make more improvements to the model we can simply load it from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_58 (Conv2D)           (None, 1022, 1022, 4)     112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 511, 511, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 509, 509, 4)       148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 254, 254, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 252, 252, 4)       148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 126, 126, 4)       0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 63504)             0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 63505     \n",
      "=================================================================\n",
      "Total params: 63,913\n",
      "Trainable params: 63,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# optimal_model = load_model('model_weights', 'model_architecture')\n",
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model\n",
    "\n",
    "We will define functions for both saving and loading the model (weights as well as architecture) from and Hadoop and JSON-formatted data.\n",
    "\n",
    "The name of the files the model will be saved to shall be: \n",
    "\n",
    "- 'model_weights.h5' (Hadoop format)\n",
    "- 'model_architecture.json' (Javascript Object Notation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, weights_file, architecture_file):\n",
    "    \"\"\"Save the model weights and architecture.\n",
    "    \n",
    "       Parameters: \n",
    "       model(Model): keras Model object being saved\n",
    "       weights_file(str): name of the Hadoop file where\n",
    "                          weights will be saved\n",
    "       architecture_file(str): name of the JSON file where \n",
    "                               model architecture is to be\n",
    "                               saved\n",
    "                               \n",
    "       Returns: None\n",
    "       \n",
    "    \"\"\"\n",
    "    # Save the weights\n",
    "    model.save_weights(f'{weights_file}.h5')\n",
    "    # Save the architecture\n",
    "    with open(f'{architecture_file}.json', 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_model(weights_file, architecture_file):\n",
    "    \"\"\"Read in the model weights and architecture.\n",
    "    \n",
    "       Parameters:\n",
    "       weights_file(str): name of the Hadoop file where\n",
    "                          weights loaded from\n",
    "       architecture_file(str): name of the JSON file where \n",
    "                               model architecture is read from\n",
    "                               \n",
    "       Returns: keras.Model: new model instantiated using the \n",
    "                             information from the files\n",
    "       \n",
    "    \"\"\"  \n",
    "    # Load Architecture\n",
    "    with open(f'{architecture_file}.json', 'r') as f:\n",
    "        new_model = model_from_json(f.read())\n",
    "    # Load Weights\n",
    "    new_model.load_weights(f'{weights_file}.h5')\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "115/115 [==============================] - 134s 1s/step - loss: 0.0062 - accuracy: 0.9963 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0165 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 2/40\n",
      "115/115 [==============================] - 129s 1s/step - loss: 4.7825e-09 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 3/40\n",
      "115/115 [==============================] - 134s 1s/step - loss: 3.7771e-11 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 4/40\n",
      "115/115 [==============================] - 120s 1s/step - loss: 5.0624e-12 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 5/40\n",
      "115/115 [==============================] - 122s 1s/step - loss: 2.3975e-12 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 6/40\n",
      "115/115 [==============================] - 126s 1s/step - loss: 1.5221e-12 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 7/40\n",
      "115/115 [==============================] - 130s 1s/step - loss: 1.0852e-12 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 8/40\n",
      "115/115 [==============================] - 126s 1s/step - loss: 8.3857e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 9/40\n",
      "115/115 [==============================] - 137s 1s/step - loss: 6.8465e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 10/40\n",
      "115/115 [==============================] - 143s 1s/step - loss: 5.8668e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 11/40\n",
      "115/115 [==============================] - 140s 1s/step - loss: 5.1620e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 12/40\n",
      "115/115 [==============================] - 133s 1s/step - loss: 4.6080e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 13/40\n",
      "115/115 [==============================] - 138s 1s/step - loss: 4.1611e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 14/40\n",
      "115/115 [==============================] - 126s 1s/step - loss: 3.7973e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 15/40\n",
      "115/115 [==============================] - 125s 1s/step - loss: 3.4969e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 16/40\n",
      "115/115 [==============================] - 130s 1s/step - loss: 3.2457e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 17/40\n",
      "115/115 [==============================] - 151s 1s/step - loss: 3.0291e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 18/40\n",
      "115/115 [==============================] - 132s 1s/step - loss: 2.8382e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 19/40\n",
      "115/115 [==============================] - 127s 1s/step - loss: 2.6734e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 20/40\n",
      "115/115 [==============================] - 129s 1s/step - loss: 2.5298e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 21/40\n",
      "115/115 [==============================] - 130s 1s/step - loss: 2.3955e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 22/40\n",
      "115/115 [==============================] - 128s 1s/step - loss: 2.2784e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 23/40\n",
      "115/115 [==============================] - 128s 1s/step - loss: 2.1760e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 24/40\n",
      "115/115 [==============================] - 127s 1s/step - loss: 2.0810e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 25/40\n",
      "115/115 [==============================] - 128s 1s/step - loss: 1.9988e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 26/40\n",
      "115/115 [==============================] - 133s 1s/step - loss: 1.9266e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 27/40\n",
      "115/115 [==============================] - 135s 1s/step - loss: 1.8614e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 28/40\n",
      "115/115 [==============================] - 128s 1s/step - loss: 1.7999e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 29/40\n",
      "115/115 [==============================] - 132s 1s/step - loss: 1.7387e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 30/40\n",
      "115/115 [==============================] - 125s 1s/step - loss: 1.6785e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 31/40\n",
      "115/115 [==============================] - 133s 1s/step - loss: 1.6222e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 32/40\n",
      "115/115 [==============================] - 134s 1s/step - loss: 1.5695e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/40\n",
      "115/115 [==============================] - 163s 1s/step - loss: 1.5206e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 34/40\n",
      "115/115 [==============================] - 1367s 12s/step - loss: 1.4747e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 35/40\n",
      "115/115 [==============================] - 138s 1s/step - loss: 1.4315e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 36/40\n",
      "115/115 [==============================] - 134s 1s/step - loss: 1.3905e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 37/40\n",
      "115/115 [==============================] - 149s 1s/step - loss: 1.3522e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 38/40\n",
      "115/115 [==============================] - 162s 1s/step - loss: 1.3161e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 39/40\n",
      "115/115 [==============================] - 152s 1s/step - loss: 1.2813e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 40/40\n",
      "115/115 [==============================] - 154s 1s/step - loss: 1.2474e-13 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# define the best model (architecture and hyper params)\n",
    "best_model = Sequential()\n",
    "\n",
    "# add convolutional layers\n",
    "add_conv_layer(best_model, 4, True, kernel_size=(2, 2), pool_size=(2, 2))\n",
    "add_conv_layer(best_model, 4, False, kernel_size=(2, 2), pool_size=(3, 3))\n",
    "add_conv_layer(best_model, 4, False, kernel_size=(1, 1), pool_size=(2, 2))\n",
    "best_model.add(Flatten())\n",
    "# add mlp layer\n",
    "add_dense_layer(best_model, 1, True, drop_rate=0.2)\n",
    "\n",
    "# compile the model\n",
    "compile_model(best_model, optimizer='rmsprop')\n",
    "\n",
    "# use tensorboard\n",
    "tensorboard = TensorBoard(log_dir='./Graph/kernel-optimized')\n",
    "\n",
    "# train the model\n",
    "batch_size, epochs = 7, 40\n",
    "train_model(best_model, df_train,\n",
    "                df_test, epochs, \n",
    "                batch_size, callbacks=[tensorboard])\n",
    "\n",
    "# save the model\n",
    "save_model(best_model, 'model_weights', 'model_architecture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling the Minority Class\n",
    "\n",
    "We need more fire!\n",
    "\n",
    "The majority of images in this dataset are currently for the \"No fire\" class. Therefore our model is now biased towards predicting this class, which makes its accuracy less reliable. \n",
    "\n",
    "In order to deal with this problem, we'll randomly duplicate some of the existing fire images in our dataset, such that the ratio of both is more balanced.\n",
    "\n",
    "Look at [this blog post](https://elitedatascience.com/imbalanced-classes?_ga=2.44533796.1624997989.1593199508-1623274989.1547664151) for more info about this concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    541\n",
       "0    541\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the DataFrame by classes\n",
    "df_no_fire = df[df['label'] == 0]\n",
    "df_fire = df[df['label'] == 1]\n",
    "# Upsampling by replacement:\n",
    "df_fire_upsampled = (\n",
    "    resample(df_fire, replace=True,\n",
    "             n_samples=len(df_no_fire), \n",
    "             random_state=123) # reproducible results\n",
    ")\n",
    "# Combine classes once more into one DataFrame\n",
    "df_upsampled = pd.concat([df_no_fire, df_fire_upsampled])\n",
    "# Verify class ratio is now 1:1\n",
    "df_upsampled['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's retrain the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "20/20 [==============================] - 101s 5s/step - loss: 1.5524e-05 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 2.4228e-09 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 98s 5s/step - loss: 3.5755e-07 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 4.3103e-10 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 86s 4s/step - loss: 1.1399e-07 - accuracy: 1.0000 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00 - val_loss: 5.8758e-11 - val_accuracy: 1.0000 - val_precision_43: 0.0000e+00 - val_recall_43: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# load the model saved previously\n",
    "# prev_biased_model = load_model('model_weights', 'model_architecture')\n",
    "# compile the model\n",
    "# compile_model(prev_biased_model)\n",
    "# train-test split the data\n",
    "df_train, df_test = split_data(df_upsampled)\n",
    "# Retrain the model\n",
    "history = train_model(best_model, df_train, df_test, epochs=3, \n",
    "                       batch_size=40, callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint: Save the model again to make life easier!\n",
    "save_model(best_model, 'model_weights', 'model_architecture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augumentation\n",
    "\n",
    "Let's add more variation to the dataset now, in order to make the model more robust!\n",
    "\n",
    "Specifically, I will be using the code from this [lesson in DS 2.2](https://github.com/Make-School-Courses/DS-2.2-Deep-Learning/blob/master/Lessons/KerasforLargeDatasets.md) in order to generate new images of fire/no fire that may have the following alterations to them:\n",
    "\n",
    "- different positions of the fire, or other objects\n",
    "- different camera angles\n",
    "- weird lighting\n",
    "\n",
    "This will better prepare the model to be used on noisy, real world data in production!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 651 images belonging to 6 classes.\n",
      "Found 651 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# define certain parameters for training\n",
    "image_dim = (1024, 1024)\n",
    "batch_size = 40\n",
    "dataset_dir = 'Fire-Detection-Image-Dataset'\n",
    "\n",
    "# Instantiate training ImageDataGenerator from Keras\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# Instantiate testing ImageDataGenerator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators for the new images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=image_dim,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=image_dim,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "20/20 [==============================] - 2748s 137s/step - loss: -17.8156 - accuracy: 0.2251 - precision_43: 0.7455 - recall_43: 0.5777 - val_loss: -64.0785 - val_accuracy: 0.2411 - val_precision_43: 0.8311 - val_recall_43: 0.9812\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 1857s 93s/step - loss: -138.3190 - accuracy: 0.2475 - precision_43: 0.8311 - recall_43: 0.9950 - val_loss: -186.5549 - val_accuracy: 0.2413 - val_precision_43: 0.8312 - val_recall_43: 0.9965\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 1667s 83s/step - loss: -399.8039 - accuracy: 0.2385 - precision_43: 0.8311 - recall_43: 0.9975 - val_loss: -502.6303 - val_accuracy: 0.2411 - val_precision_43: 0.8311 - val_recall_43: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'history = train_model(optimal_model, df_train, df_test, epoch=3, \\n                       batch_size=40, callbacks=[tensorboard])'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model saved previously\n",
    "# prev_no_aug_model = load_model('model_weights', 'model_architecture')\n",
    "# Compile the model\n",
    "# compile_model(prev_no_aug_model)\n",
    "# Train the model on augmented images, increased steps per epoch and validation steps\n",
    "history = best_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=20,\n",
    "        epochs=3,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint: Save the model again to make life easier!\n",
    "save_model(best_model, 'model_weights', 'model_architecture')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Overall, how well did our model perform? In this section we will evaluate by understanding the following metrics, for how well the model classified validation data:\n",
    "\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n",
    "\n",
    "We will begin by loading in the model again, and compiling as well as training it such that it outputs accuracy, loss, precision, recall, and F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = load_model('model_weights', 'model_architecture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "40/40 [==============================] - 1770s 44s/step - loss: -2064.7081 - accuracy: 0.2426 - precision_46: 0.8369 - recall_46: 1.0000 - val_loss: -3746.1863 - val_accuracy: 0.2412 - val_precision_46: 0.8311 - val_recall_46: 1.0000\n",
      "Epoch 2/7\n",
      "40/40 [==============================] - 1677s 42s/step - loss: -9694.1369 - accuracy: 0.2425 - precision_46: 0.8310 - recall_46: 1.0000 - val_loss: -12717.8857 - val_accuracy: 0.2413 - val_precision_46: 0.8310 - val_recall_46: 1.0000\n",
      "Epoch 3/7\n",
      "40/40 [==============================] - 1758s 44s/step - loss: -26773.7618 - accuracy: 0.2373 - precision_46: 0.8310 - recall_46: 1.0000 - val_loss: -58964.2383 - val_accuracy: 0.2408 - val_precision_46: 0.8310 - val_recall_46: 1.0000\n",
      "Epoch 4/7\n",
      "40/40 [==============================] - 1762s 44s/step - loss: -58667.9935 - accuracy: 0.2387 - precision_46: 0.8310 - recall_46: 1.0000 - val_loss: -67866.7109 - val_accuracy: 0.2413 - val_precision_46: 0.8309 - val_recall_46: 1.0000\n",
      "Epoch 5/7\n",
      "40/40 [==============================] - 1700s 42s/step - loss: -109780.0350 - accuracy: 0.2458 - precision_46: 0.8310 - recall_46: 1.0000 - val_loss: -142306.4844 - val_accuracy: 0.2414 - val_precision_46: 0.8310 - val_recall_46: 1.0000\n",
      "Epoch 6/7\n",
      "40/40 [==============================] - 4572s 114s/step - loss: -190510.7303 - accuracy: 0.2465 - precision_46: 0.8310 - recall_46: 1.0000 - val_loss: -324094.5000 - val_accuracy: 0.2410 - val_precision_46: 0.8310 - val_recall_46: 1.0000\n",
      "Epoch 7/7\n",
      "40/40 [==============================] - 2431s 61s/step - loss: -307029.1057 - accuracy: 0.2432 - precision_46: 0.8310 - recall_46: 1.0000 - val_loss: -422453.5000 - val_accuracy: 0.2412 - val_precision_46: 0.8310 - val_recall_46: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "compile_model(model, optimizer='rmsprop')\n",
    "\n",
    "# train model with callbacks, get history\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=40,\n",
    "        epochs=7,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800,\n",
    "        callbacks=[EarlyStopping(monitor='val_accuracy', patience=2)]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "# calculate f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's verify the metrics we have available to us for plotting, in the `history` object returned by the training above (with augmented data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'val_precision_46', 'val_recall_46', 'loss', 'accuracy', 'precision_46', 'recall_46'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(metric):\n",
    "    \"\"\"Plots the model performance metric for training\n",
    "       testing data using Matplotlib.\n",
    "       \n",
    "       Parameters\n",
    "       metric(str): the name of the metric. Will be one of \n",
    "                    the keys in the History object, e.g. 'loss'\n",
    "       \n",
    "       Returns: None\n",
    "       \n",
    "    \"\"\"\n",
    "    if metric == 'precision' or metric == 'recall':\n",
    "        metric += '_46'\n",
    "    # plot for training data\n",
    "    plt.plot(history.history[metric])\n",
    "    # plot for testing data\n",
    "    val_form = f'val_{metric}'\n",
    "    plt.plot(history.history[val_form])\n",
    "    # add meta-info about graph - title, labels, legend\n",
    "    plt.title(f'Model {metric}')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    # show the graph\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score\n",
    "```\n",
    "F1-Score = (2 * Precision * Recall) / (Precision + Recall)\n",
    "```\n",
    "This value below is an approximate answer, using estimated values for validation precision and recall from the graphs above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score of the Optimized Model: 0.908\n"
     ]
    }
   ],
   "source": [
    "def f1_score(precision, recall):\n",
    "    \"\"\"Return the F1-Score.\n",
    "    \n",
    "       Parameters:\n",
    "       precision(float): a proportion of the model's accurate positive predictions,\n",
    "                         out of all the positive predictions made by said model\n",
    "       recall(float): a proportion of the model's accurate positive predictions,\n",
    "                      to all the samples which were truly positive (TP and FN)\n",
    "                    \n",
    "       Returns: float: the F1-Score is a function of both precision and recall,\n",
    "                which especially becomes useful in datasets with unequal\n",
    "                distribution of classes\n",
    "    \n",
    "    \"\"\"\n",
    "    return (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "f1 = f1_score(0.831, 1.000)\n",
    "print(f'F1-Score of the Optimized Model: {round(f1, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Conclusions\n",
    "\n",
    "Ultimately, the model constructed had a validation accuracy of approximately 24.1% - this is bewildering, as the model still managed to score about 83.1% on validation precision, 99.9% on validation recall, and 0.907 for the F1-Score. This would suggest that the model is classifying both the minority and majority classes alright. \n",
    "\n",
    "To take this analysis further, I would train the model again and do the following:\n",
    "\n",
    "- Use the `EarlyStopping` callback function to get the best validation accuracy\n",
    "- Implement a function to exactly compute the F1-Score\n",
    "- Find the optimal kernel size\n",
    "- Find the optimal layer size for both the `Conv2D` and `Dense` layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
